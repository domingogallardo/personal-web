---
title: "¬øAGI o no AGI? (#14 de 2024)"
date: 2024-09-13
draft: false
tags:
  - "newsletter"
---
<p>Despu√©s de un descanso veraniego, esta semana os traigo otro art√≠culo especial, en el que, en lugar de repasar lo sucedido en la √∫ltima quincena, comento un √∫nico tema. Pero no os asust√©is, esta vez va a ser bastante m√°s corto que aquel que hice a finales de mayo sobre <a href="/posts/los-papiros-de-herculano-9-de-2024/">los papiros de Herculano</a> üòÑ.</p>

<p>La semana que viene volveremos a nuestra programaci√≥n quincenal, con un n√∫mero en el comentaremos algunas noticias del verano y la sorpresa de ayer: el <a href="https://openai.com/o1/">nuevo modelo de OpenAI</a>. </p>

<p>¬°Gracias por leerme! Y un abrazo a los suscriptores reci√©n llegados.</p>

<p>
</p>

<p>
<img src="agi-or-not.jpg" alt="">
</p>

<p>Imagen generada por Grok. Prompt: ‚ÄúA computer scientist angrily arguing with a colleague over a blackboard about the definition of AGI‚Äù.</p>

<p>√öltimamente el t√©rmino AGI (Artificial General Intelligence, Inteligencia Artificial General) est√° en boca de casi todo el mundo. Podcasts, blogs, redes sociales, newsletters, todos hablan de si vamos a alcanzar la AGI en X a√±os o no. </p>

<p>Antes de arriesgarme a hacer ninguna predicci√≥n quiero dedicarle un rato a hablar del propio t√©rmino. ¬øTiene sentido hablar de AGI? ¬øO se ha convertido en un <strong>t√©rmino maldito</strong>, no recomendable, desde que gente como Altman y OpenAI no para de usarlo? ¬øTe van a mirar mal si hablas de AGI?</p>

<p>Vamos a empezar con una an√©cdota de la semana pasada.</p>

<p>Hace a√±os segu√≠a por Twitter a <strong>Grady Booch</strong>. Fue una figura importante de la ingenier√≠a del software de los a√±os 80, en los que puso de moda metodolog√≠as de dise√±o orientadas a objetos muy interesantes. Todav√≠a tengo un par de libros suyos de aquella √©poca.</p>

<p>Cuando empezaron a hacerse p√∫blicos los primeros modelos generativos, Booch se puso tambi√©n a hablar de IA. Al principio era interesante, resaltaba las limitaciones y los problemas de estos modelos y su voz era un buen contrapunto a apocal√≠pticos exagerados como <strong>Sam Harris</strong> o <strong>Nick Bostrom</strong>. Sin embargo, su <em>timeline</em> se convirti√≥ pronto en un sonsonete del estilo del de <strong>Gary Marcus</strong>, todo negativo, todo problem√°tico. Un d√≠a, no recuerdo con qu√© post, me enfad√©, me puse en modo <strong>Van Gaal</strong> y dej√© de seguirle.</p>

<p>Pero hace poco el algoritmo de X me mostr√≥ la siguiente <a href="https://x.com/fchollet/status/1831728150914744362">interacci√≥n de Fran√ßois Chollet con √©l</a>:</p>

<p>
<img src="Pasted image 20240911132559.png" alt="">
</p>

<p>Grady Booch:</p>

<blockquote>
<p>AGI no suceder√° en tu vida. Ni en la vida de tus hijos. Ni en la vida de los hijos de tus hijos.</p>

</blockquote>

<p>El post de Booch era de hace de m√°s de un a√±o pero por alguna raz√≥n Chollet lo vio hace unos d√≠as. Fran√ßois es un chico majo (es verdad, mirad&nbsp;<a href="https://www.youtube.com/watch?v=UakqL6Pj9xo">alguno de sus v√≠deos en YouTube</a>) y, en lugar de hacer como yo y dejar de seguir a Booch, le contest√≥ con buenas maneras:</p>

<blockquote>
<p>En mi propia definici√≥n de AGI, suceder√° definitivamente en mi vida, de hecho es probable que en los pr√≥ximos 10-15 a√±os. Pero mi definici√≥n personal es m√°s tangible y m√°s restrictiva que la mayor√≠a, para mi no es "una mente humana artificial" ni "un dios artificial". AGI es solo una IA que posee un grado de generalidad (habilidad de enfrentarse a problemas nuevos y entenderlos) al menos tan alto que el de los humanos. Hasta el momento la generalidad ha sido el ingrediente que falta en la IA. Pronto podr√≠amos conseguir desarrollarlo.</p>

</blockquote>

<p>Booch le responde haciendo un chascarrillo con lo de la "generalidad":</p>

<p>
<img src="Pasted image 20240911134011.png" alt="">
</p>

<blockquote>
<p>En general :-) estoy de acuerdo contigo, excepto que, en general, hablando, esas medidas de generalidad son tan vagas que hacen que el list√≥n para el √©xito sea bastante bajo.</p>

</blockquote>

<p>Est√° claro que Booch no conoce todo el trabajo que est√° haciendo Chollet con su <strong>Premio ARC</strong> (<a href="https://arcprize.org/">arcprice.org</a>&nbsp;y&nbsp;<a href="https://x.com/arcprize">X</a>), precisamente para intentar medir de una forma objetiva algo de esta "generalidad" necesaria para la AGI. Ya hablamos de este premio en el post de la&nbsp;<a href="/posts/del-1-al-15-de-junio-11-de-2024/">primera quincena de junio</a>.</p>

<p>Chollet ya no le contest√≥. Lo que no s√© es si, como yo, dej√≥ de seguirle.</p>

<div>
<hr>

</div>
<p>Lo anterior no es solo una an√©cdota. La falta de entendimiento sobre el t√©rmino AGI se est√° haciendo cada vez m√°s intensa. Y ahora se complica todo a√∫n m√°s con su uso cada vez m√°s extendido fuera del √°mbito cient√≠fico. Directivos de startups, aspirantes a influencers en X o YouTube, muchos usan el t√©rmino principalmente para llamar la atenci√≥n y captar audiencia (o dinero).</p>

<p>Pero la popularidad del t√©rmino tambi√©n tiene sus cosas buenas. Programas generalistas est√°n us√°ndolo para explicar cosas interesantes haciendo buena divulgaci√≥n cient√≠fica. Por ejemplo, <strong>The Economist</strong>, en su siempre interesante podcast semanal&nbsp;<a href="https://podcasts.apple.com/us/podcast/babbage-from-the-economist/id508376907">Babbage</a>, ha publicado un especial sobre AGI (<a href="https://podcasts.apple.com/es/podcast/babbage-from-the-economist/id508376907?i=1000668393081">AGI, part one: what is artificial general intelligence?</a>). En el programa se intenta dar una visi√≥n bastante acad√©mica, entrevistando a distintos perfiles como ingenieros, cient√≠ficos de la computaci√≥n o neurocient√≠ficos.</p>

<p>
<a href="https://x.com/MelMitchell1">Melanie Mitchell</a>, cient√≠fica de IA muy puesta en IA tradicional pero tambi√©n en LLMs (ver por ejemplo su art√≠culo&nbsp;<a href="https://oecs.mit.edu/pub/zp5n8ivs/release/1?readingCollection=9dd2a47d">Large Language Models</a>&nbsp;en&nbsp;<a href="https://oecs.mit.edu/">The Open Encylopedia of Cognitive Science</a>) comenta una definici√≥n relacionada con las capacidades humanas:</p>

<blockquote>
<p>AGI se ha definido  como una m√°quina que es capaz de hacer todo lo que un ser humano puede hacer. Y luego, recientemente, se ha debilitado un poco esta, defini√©ndose como una m√°quina que puede realizar todas las <strong>tareas cognitivas</strong> que un ser humano puede hacer, dejando de lado las formas f√≠sicas de inteligencia.</p>

</blockquote>

<p>Aunque despu√©s resalta que&nbsp;<strong>no le gusta demasiado</strong>&nbsp;el t√©rmino AGI:</p>

<blockquote>
<p>
<strong>Presentador</strong>: ¬øCrees que el uso de la frase AGI es realmente √∫til para los cient√≠ficos en inteligencia artificial como t√∫, o lo ves m√°s como una distracci√≥n?</p>

<p>
<strong>Mitchell</strong>: Creo que es un poco <strong>una distracci√≥n</strong>. La gente siente que puede tomar la inteligencia como algo que est√° separado de su manifestaci√≥n en los humanos, en el cerebro y el cuerpo humano, y aislarla [...]. Y no estoy convencida de que eso sea realmente significativo o que nos d√© una direcci√≥n clara a seguir.</p>

</blockquote>

<p>Sin embargo, el cient√≠fico de Google&nbsp;<a href="https://x.com/blaiseaguera">Blaise Aguera y Arcas</a>, no se pierde en disquisiciones sobre el t√©rmino y dice que el problema no es de hacer los modelos m√°s generales, sino de&nbsp;<strong>hacerlos mejores</strong>&nbsp;en distintos aspectos:</p>

<blockquote>
<p>Creo que <strong>se trata simplemente de mejorar</strong> en un mont√≥n de cosas que a todos nos importan, como la veracidad, el razonamiento, la memoria, la planificaci√≥n, tener una perspectiva consistente durante largos periodos de tiempo, y as√≠ sucesivamente [...] As√≠ que no creo que se trate de cu√°n lejos estamos de algo en particular, sino m√°s bien de qu√© tan r√°pido est√°n mejorando estas cosas, y cu√°ndo se volver√°n confiables para hacer una variedad de cosas diferentes que, en este momento, dir√≠a que no son confiables para hacer de manera aut√≥noma.</p>

</blockquote>

<p>O sea, que no hay acuerdo ni siquiera entre los cient√≠ficos que est√°n m√°s metidos en el tema. Unos dicen que AGI no es un t√©rmino √∫til, otros que s√≠, porque precisamente lo que hace falta es eso, generalizar. Y otros dicen que casi ya estamos ah√≠, y que solo falta mejorar. </p>

<div>
<hr>

</div>
<p>¬øCu√°l es mi opini√≥n? ¬øAGI o no AGI? </p>

<p>Para mi, como dice <strong>Chollet</strong>, la clave est√° en la "G" del t√©rmino: ‚Äúgeneral‚Äù. Esta "G" simboliza un cambio significativo en la evoluci√≥n de la inteligencia artificial y de las redes neuronales, pasando de modelos especializados, como los que dominaron en la d√©cada de 2010, hacia modelos m√°s gen√©ricos y polivalentes como los actuales LLMs, que son capaces de almacenar todo el conocimiento humano e interaccionar en lenguaje natural. </p>

<p>Y, como dice <strong>Aguera y Arcas</strong>, nos iremos acercando a esta ‚ÄúG‚Äù conforme se vayan desarrollando nuevos algoritmos que mejoren las carencias de los actuales LLMs dot√°ndoles de nuevas capacidades que les permitan resolver problemas como el premio ARC de <strong>Chollet</strong>. </p>

<p>Yo, por mi parte, <strong>seguir√© hablando de AGI</strong>, aunque cada vez que lo haga tenga que referenciar este art√≠culo para que no me confundan con un AI Bro.</p>

<p>
<img src="448a4164-85a4-4217-bb33-a8be1efed740_1024x1024.png" alt="">
</p>

<p>Imagen generada por ChatGPT 4o. Prompt: ‚ÄúHaz una imagen de un AI Bro‚Äù.</p>

<div>
<hr>

</div>
<p>¬°Hasta la pr√≥xima quincena, nos leemos! üëãüëã</p>

<p>
</p>
