---
title: "Hofstadter, Penrose y el \"sentimiento de conciencia consciente\""
date: 2025-09-25
draft: false
tags:
  - "newsletter"
---

[Post en esta web](/posts/hofstadter-penrose-y-el-sentimiento-de-conciencia-consciente/)

![](image-2.webp)

_Penrose, Hofstadter y Escher: tres autores que han moldeado mis opiniones sobre el tema de la conciencia._

Hace cuarenta aÃ±os leÃ­ dos libros que me marcaron:Â _**GÃ¶del, Escher, Bach**_Â deÂ **Douglas R. Hofstadter**Â yÂ _**The Emperorâ€™s New Mind**_Â deÂ **Roger Penrose**. Durante dÃ©cadas los vi como visiones casi opuestas: Hofstadter se posicionaba a favor de que la IA terminarÃ­a construyendo mentes artificiales gracias al dominio de laÂ **estructura**, sÃ­mbolos, bucles y de los distintos niveles del lenguaje. Penrose, por otro lado, argumentaba que un algoritmo nunca podrÃ¡ simularÂ **lo que se siente**Â al estar consciente.

Cuatro dÃ©cadas despuÃ©s ha ocurrido algo que me obliga a releerlos: la irrupciÃ³n de losÂ **modelos de lenguaje**Â entrenados exclusivamente con texto. Sin cÃ¡maras ni sensores, estas mÃ¡quinas aprenden sintaxis y capturan regularidades semÃ¡nticas de uso: hablan, resumen, programan, argumentan. No resuelven la conciencia, pero sÃ­ reencuadran el mapa: muestran que buena parte del â€œintelecto lingÃ¼Ã­sticoâ€ puede ponerse en pie solo con lenguaje.

## Douglas R. Hofstadter

En 1987, cuando estudiaba tercero de InformÃ¡tica en Alicante, vi en la librerÃ­a 80 Mundos un libro gris, enorme, de un autor que conocÃ­a por los artÃ­culos matemÃ¡ticos de la revista InvestigaciÃ³n y Ciencia,Â **Douglas R. Hofstadter**. Lo hojeÃ© y, al momento, me asombraron las extraordinarias ilustraciones de Escher, la maquetaciÃ³n de un texto complejÃ­simo â€”con diÃ¡logos, deducciones lÃ³gicas, largas citas, juegos tipogrÃ¡ficos, programas de ordenador, etc.â€” y la cantidad de temas interesantÃ­simos que recorrÃ­an sus casi 900 pÃ¡ginas. Era la traducciÃ³n al espaÃ±ol deÂ **GÃ¶del, Escher, Bach**Â (GEB), publicada por Tusquets.

Leyendo el libro, parecÃ­a que Hofstadter se alineaba con lo que entonces se llamabaÂ **IA fuerte**Â **(Strong AI)**, la idea de que podremos crear un programa que simule completamente la mente humana, incluida la conciencia. Alan Turing, en su famoso artÃ­culoÂ **Computing Machinery and Intelligence**Â (1950), fue uno de los primeros en defender algo asÃ­.

IntentÃ© entender sus argumentos; sin embargo, habÃ­a cosas que no me convencÃ­an. Â¿Simular la sensaciÃ³n de conciencia? Â¿La sensaciÃ³n deÂ _yo_? Â¿La sensaciÃ³n de estar viendo algoÂ _rojo_? Â¿Puede un programa de ordenador generar eso?Â 

Recordemos que el propio Hofstadter explica en el libro la idea, importante y heredera de Turing, de que la ejecuciÃ³n de un programa no es mÃ¡s que aplicar un conjunto de reglas discretas. No habrÃ­a diferencia conceptual entre un microprocesador ejecutando instrucciones y unos monjes que copian ceros y unos en una cinta de papel. No entendÃ­a cÃ³mo a Hofstadter (o incluso a Turing) no les parecÃ­a absurda esta idea. Â¿CÃ³mo pueden creer posible que surja "conciencia" del proceso de borrar y escribir ceros y unos en un papel? Â¿QuÃ© ven ellos que yo no veo?

## Roger Penrose

Esta duda aumentÃ³ un par de aÃ±os despuÃ©s, en 1989, cuando el fÃ­sicoÂ **Roger Penrose**, publicÃ³ su famoso libroÂ **The Emperors New Mind**. Me comprÃ© la ediciÃ³n en inglÃ©s el aÃ±o siguiente, en 1990. LeÃ­ Ã¡vidamente sus argumentos contrarios a la IA fuerte, intentÃ© leer (sin Ã©xito) toda su explicaciÃ³n sobre la mecÃ¡nica cuÃ¡ntica y cosmologÃ­a; y me maravillÃ© con sus magnÃ­ficas ilustraciones a tinta (Penrose es un excelente dibujante y admirador tambiÃ©n de Escher).

![](img_7803-1-2.webp)

_InterpretaciÃ³n de Penrose de una mÃ¡quina de Turing procesando una cinta infinita._

La tesis de Penrose â€”que me convenciÃ³ y en la que sigo creyendoâ€” es que la conciencia humana no es algorÃ­tmica: no puede capturarse con una mÃ¡quina de Turing convencional. En el libro utiliza, entre otras cosas, el teorema de incompletitud de GÃ¶del. MÃ¡s allÃ¡ de los detalles, me quedÃ© sobre todo con sus crÃ­ticas a la posibilidad de simular mediante un algoritmo los aspectos mÃ¡s profundos de la conciencia como laÂ _awareness_Â o laÂ _sentience_(sensaciÃ³n de estar consciente, advertir, percibir).

## M. C. Escher como punto de conexiÃ³n

Penrose y Hofstadter coinciden en algo: la admiraciÃ³n por Escher. Pero cada uno destaca aspectos distintos.

Penrose destaca las paradojas visuales de Escher, la consistencia local que se vuelve imposibilidad global: cada peldaÃ±o tiene sentido, pero el conjunto viola la geometrÃ­a fÃ­sica. Los Penrose (Roger y su padre, Lionel) popularizaron el triÃ¡ngulo imposible y la escalera infinita que Escher convirtiÃ³ en arte visual enÂ **[Ascending and Descending](https://escherinhetpaleis.nl/en/about-escher/escher-today/ascending-and-descending)**Â yÂ **[Waterfall](https://escherinhetpaleis.nl/en/about-escher/masterpieces/waterfall)**: metÃ¡foras de cÃ³mo reglas discretas, aparentemente inocuas, pueden producir paradojas y lÃ­mites a lo computable.

![](impossible_staircase_triangle.webp)

_La escalera infinita y el triÃ¡ngulo imposible: dos figuras ideadas por Roger y su padre Lionel Penrose._


Hofstadter, por su parte, resalta obras comoÂ **[Drawing Hands](https://escherinhetpaleis.nl/en/about-escher/masterpieces/drawing-hands)**,Â **[Relativity](https://escherinhetpaleis.nl/en/about-escher/masterpieces/relativity)**Â oÂ **[Print Gallery](https://escherinhetpaleis.nl/en/about-escher/masterpieces/print-gallery)**Â en las que se visualiza la idea de â€œbucle extraÃ±oâ€ (_strange loop_): niveles que se referencian unos a otros sin comienzo ni final claros. CÃ­rculos recursivos y autorreferentes que, para Hofstadter, son esenciales para entender la conciencia y el "yo".

Un dibujo que me gusta especialmente esÂ **Magic Mirror**, que combina muchos de esos elementos: espejos, realidad e ilusiÃ³n, bucles extraÃ±os y teselaciones. Es un buen resumen de todos los conceptos anteriores.

![](338_toverspiegel-1-1.webp)

_Grabado de Escher Magical mirror (1946), en elÂ [Museum Escher in Het Paleis](https://escherinhetpaleis.nl/en/about-escher/masterpieces)._

## CrÃ­tica a la IA fuerte: el â€œLibro de Einsteinâ€

Un ejemplo de Penrose que siempre me ha acompaÃ±ado es su crÃ­tica de la idea de Hofstadter de un libro que contenga la mente de Einstein y con el que podemos interactuar haciÃ©ndole preguntas. Si la IA fuerte es posible,Â **podrÃ­a simularse la mente de Einstein**. Penrose planteaba preguntas que, para mi, vuelven absurda la idea:

> Would Einsteinâ€™s awareness be enacted only when the book is being so examined? Would he be aware twice over if two people chose to ask the book the same question at two completely different times? Or would that entail two separate and temporally distinct instances of the same state of Einsteinâ€™s awareness? Perhaps his awareness would be enacted only if the book is changed? [...] Or would the book-Einstein remain completely self-aware even if it were never examined or disturbed by anyone or anything? [...] What does it mean to activate an algorithm, or to embody it in physical form? Would changing an algorithm be different in any sense from merely discarding one algorithm and replacing it with another? What on earth does any of this have to do with our feelings of conscious awareness?

TraducciÃ³n (mÃ­a):

> Â¿La consciencia (_awareness_) de Einstein se manifestarÃ­a solo cuando el libro estuviera siendo examinado? Â¿SerÃ­a consciente dos veces si dos personas eligieran hacerle al libro la misma pregunta en dos momentos completamente distintos? Â¿O eso implicarÃ­a dos instancias separadas y temporalmente distintas del mismo estado de consciencia de Einstein? Â¿QuizÃ¡ su consciencia se pondrÃ­a en acto Ãºnicamente si el libro cambia? [â€¦] Â¿O permanecerÃ­a el libro-Einstein completamente autoconsciente (_self-aware_) incluso si nunca fuera examinado o perturbado por nadie o por nada? [â€¦] Â¿QuÃ© significa activar un algoritmo, o encarnarlo en forma fÃ­sica? Â¿SerÃ­a distinto cambiar un algoritmo en algÃºn sentido de simplemente descartar uno y sustituirlo por otro? Â¿QuÃ© tiene que ver todo esto con nuestros sentimientos de conciencia consciente?

Hofstadter no llega a responder estas preguntas: las esquiva, sin entrar en el problema fundamental de la conciencia consciente (_conscious awareness_).

## Cuatro puntos de vista (segÃºn Penrose)

EnÂ **Shadows of the Mind (1994)**Â Penrose concreta su posiciÃ³n y, antes, delimita cuidadosamente a quÃ© llama â€œconcienciaâ€:

> How do our feelings of conscious awareness -of happiness, pain, love, aesthetic sensibility, will, understanding, etc.- fit into such a computational picture? [...]

TraducciÃ³n:

> Â¿CÃ³mo encajan nuestras sensaciones de conciencia consciente (*conscious awareness*)â€”de felicidad, dolor, amor, sensibilidad estÃ©tica, voluntad, comprensiÃ³n, etc.â€”en un marco computacional como ese?

Penrose subrayaÂ ***feelings of conscious awareness***: no le basta con simular conductas; se estÃ¡ refiriendo al problema mÃ¡s fundamental de la conciencia, a la sensaciÃ³n de estar despierto, sintiendo sensaciones, experimentando la realidad.

Luego plantea cuatro posiciones alternativas:

> Me parece que hay al menos cuatro posturas â€”o extremos de posturaâ€” que razonablemente se pueden sostener sobre el asunto:
>
> 1. **Todo pensamiento es computaciÃ³n**; en particular, las sensaciones de conciencia consciente (*conscious awareness*) se suscitan simplemente mediante la realizaciÃ³n de las computaciones adecuadas.
> 2. La consciencia (*awareness*) es una caracterÃ­stica de la acciÃ³n fÃ­sica del cerebro; y aunque cualquier acciÃ³n fÃ­sica puede simularse computacionalmente,Â **la simulaciÃ³n computacional por sÃ­ sola no puede suscitar consciencia**Â (*awareness*).
> 3. Una acciÃ³n fÃ­sica apropiada del cerebro suscita consciencia (*awareness*), pero esa acciÃ³n fÃ­sicaÂ **ni siquiera puede simularse adecuadamente por medios computacionales**.
> 4. La consciencia (*awareness*)Â **no puede explicarse en tÃ©rminos fÃ­sicos**, computacionales ni de ningÃºn otro tipo cientÃ­fico.
>
> El punto de vista 3 es el que considero mÃ¡s cercano a la verdad.

La opciÃ³n 1 suele asociarse a computacionalismo/**funcionalismo**; la 2, alÂ **naturalismo biolÃ³gico**; la 3 podrÃ­a denominarseÂ **fisicalismo no computacional**Â (hay procesos fÃ­sicos no computables implicados en la conciencia); y la 4 se alinea con idealismo o con ciertas variantes deÂ **misterianismo**Â (lo consciente como intrÃ­nsecamente inaccesible a la ciencia).

Penrose se alinea con laÂ **opciÃ³n 3**. Poniendo las cartas sobre la mesa, yo voto por laÂ **opciÃ³n 4**. Creo las sensaciones conscientes son algo misterioso cuya explicaciÃ³n estÃ¡, por su carÃ¡cter personal eÂ [inefable](https://seantrott.substack.com/p/language-models-and-the-ineffable?r=hbwh&utm_medium=ios&triedRedirect=true), fuera del alcance de la explicaciÃ³n cientÃ­fica objetiva. Â¿TÃº que opinas?

## Â¿Y quÃ© hacÃ­a Hofstadter con los sentimientos?

Volvamos a la pregunta de Penrose:

> How do ourÂ **feelings of conscious awareness**Â -of happiness, pain, love, aesthetic sensibility, will, understanding, etc.- fit into such a computational picture? [...]

Es notable el cuidado con el que escogeÂ _feelings of conscious awareness_. PodrÃ­a haber dichoÂ _feelings_,Â _consciousnes_Â oÂ _awareness_Â por separado; las reÃºne y, despuÃ©s, enumera sensaciones concretas: sensaciones de consciencia consciente de felicidad; sensaciones de consciencia consciente de dolor; sensaciones de consciencia consciente de voluntad, sensibilidad, entendimiento, etc.

Penrose no se conforma con una perspectiva funcional (el â€œque se comporte como siâ€ del test de Turing). Busca la vivencia, la experiencia fenomÃ©nica. Si decimos que una IA puede igualar a un ser humano, Penrose exige que sienta como sentimos los humanos: unÂ _sentimiento de conciencia consciente_.

Â¿Y Hofstadter? Releyendo GEB, no encuentro una posiciÃ³n nÃ­tida sobre los sentimientos. Hacia el final, en "Inteligencia y emociones", intenta desligar ambos conceptos. Abre con la escena de un niÃ±o que llora porque ha explotado su globo, y concluye:

> Se podrÃ­a objetar que, aun cuando el programaÂ **â€œentiendaâ€ lo que se dice, en un sentido intelectual**, jamÃ¡s lo comprenderÃ¡ realmente, hasta que no haya llorado y llorado. Â¿Y cuÃ¡ndo conseguirÃ¡ semejante cosa una computadora? Esta es la clase de planteamiento humanÃ­stico al que se aboca Joseph Weizenbaum en su libroÂ _Computer Power and Human Reason_; pienso, por mi parte, que es un tema importante: en realidad, un tema verdaderamente muy profundo. Por desdicha,Â **muchos investigadores de IA se muestran poco dispuestos, en la actualidad, a considerar seriamente este problema**. En alguna medida, con todo, los asiste la razÃ³n, pues es un poco prematuro dedicarse ahora al llanto de las computadoras:Â **primero, es necesario ocuparse de las reglas que permitan a las computadoras habÃ©rselas con el lenguaje**Â y con otras cosas; en su oportunidad, nos enfrentaremos en cuestiones de mayor profundidad.

Los resaltados son mÃ­os. Me parece revelador: Hofstadter separa lo "intelectual" â€”las reglas para tratar con el lenguajeâ€” de los sentimientos. Y esto incluirÃ­a, en mi opiniÃ³n, el "sentimiento de ser consciente" del que habla Penrose.

GEB habla de sÃ­mbolos, significados, estructuras formales: elÂ **intelecto**. Hofstadter considera que ahÃ­ estÃ¡ lo fundamental de nuestra mente. Tal vez por esoÂ [se horrorizÃ³ cuando se dio cuenta de que una IA habÃ­a dominado esta vertiente de nuestra conducta](https://domingogallardo.substack.com/i/150656851/criticos-y-apocalipticos).

## ElÂ _plot twist_Â de los modelos de lenguaje

En la Ãºltima dÃ©cada hemos visto algo sorprendente:Â **modelos de lenguaje**Â (LLMs) entrenados exclusivamente con texto, sin entradas sensoriales ni motoras, aprenden a manipular estructuras sintÃ¡cticas y a manejar regularidades semÃ¡nticas de uso: mantienen la referencia en un diÃ¡logo, siguen instrucciones complejas, resumen, traducen, argumentan, programan. Todo ello sin haber â€œtocadoâ€ el mundo mÃ¡s allÃ¡ de lo que estÃ¡ implÃ­cito en los corpus escritos.

No prueba nada definitivo sobre la conciencia, pero sÃ­ reencuadra el mapa: muestra que una gran parte de la competencia lingÃ¼Ã­stica y del razonamiento textual puedeÂ **emerger del propio lenguaje**. Mucho de lo que asociÃ¡bamos al â€œintelecto lingÃ¼Ã­sticoâ€ puede aprenderse solo con texto.Â 

Eso no resuelve el enigma de sentir, pero sÃ­ aclara que hablar, razonar y mantener coherencia referencial no implican por sÃ­ mismos haber sentido nada.

## Una nueva perspectiva

Con esta lente actual, vuelvo a Hofstadter y Penrose para entender mejor quÃ© discutÃ­an realmente â€”y por quÃ©, quizÃ¡, no estaban tan en desacuerdo.

A ojos de Hofstadter, los modelos de lenguaje podrÃ­an verse como la confirmaciÃ³n de que los patrones simbÃ³licos y los bucles de referencia son suficientes para el razonamiento. A ojos de Penrose, confirmarÃ­an que el dominio del lenguaje no necesita la experiencia vivida.

Casi cuarenta aÃ±os despuÃ©s de mi primera lectura deÂ _GEB_, releerlo con esta perspectiva resulta muy sugerente. Hofstadter no aborda el sentimiento de ser consciente; habla de sÃ­mbolos y lenguaje. Penrose, en cambio, habla de sensaciÃ³n de ser consciente. QuizÃ¡ no estaban tan enfrentados: discutÃ­an sobre palabras ambiguas. Cada uno entendÃ­a de modo distinto â€œmenteâ€ y â€œconcienciaâ€.

En el prÃ³ximo artÃ­culo quiero desambiguar la palabra â€œconcienciaâ€ (_consciousness_) con un divertido juego tipolÃ³gico:Â **conciencia tipo-1, tipo-2 y tipo-3**.Â 

Lo cuento en un par de semanas.

---

Â¡Hasta la prÃ³xima, nos leemos! ğŸ‘‹ğŸ‘‹
