---
title: "Marzo en X"
date: 2025-04-07
draft: false
tags:
  - "personal"
---

![](image-1.webp)

En marzo he hablado en X de: 

> LLMs, GPT-4.5, GPT-4o, DeepSeek, razonamiento, Chain-of-Thought (CoT), Reinforcement Learning, cognitive behaviors (verification, backtracking, subgoals, backward chaining), continuous online reinforcement learning, misbehavior, reward hacking, modelos open source, benchmark (ARC-AGI, Aider Polyglot), context window, prompt engineering, metaficciÃ³n, escritura creativa de IA, multimodalidad, Code Interpreter, automatizaciÃ³n del desarrollo software, mantenibilidad del cÃ³digo, frontera desigual (jagged frontier), transformaciÃ³n del trabajo, infraestructura abierta, coste y escalado de inferencia, polÃ­tica tecnolÃ³gica, cultura derivada, IA encarnada (Embodied AI), autonomÃ­a, creatividad computacional, usuarios expertos, crÃ­tica polÃ­tica.

Entre otros, he citado a:

> @OpenAI, @emollick, @karpathy, @sama, @antonello, @simonw, @gallir, @JorgeGalindo, @kikollan, @ARCPrize, @paulgauthier, @ArtificialAnlys, @mattturck, @MillionInt, @fchollet, @demishassabis, @ESA_Hera, @hardmaru, @EpochAIResearch, @AnthropicAI, @mlstreettalk, @patrickc, @FranGallegoBR, @Azicuetano, @monospodcast, @KevinRoose, @dwarkesh_sp, @matiass, @TheOfficialACM, @ID_AA_Carmack, @error500 y @press_stripe

A continuaciÃ³n, la lista cronolÃ³gica de posts escritos, comentados y reposteados. La descripciÃ³n de las imÃ¡genes ha sido generada por GPT-4o.

----
ğŸ” RT 2:18 PM Â· Mar 1, 2025 **ian bremmer @ianbremmer** 

unified and strong european twitter statements of support for ukraine over last day. theyâ€™re worth the paper they arenâ€™t printed on.

the europeans have to show they are prepared to defend ukraine without the americans. the future of europe depends on it.

----
ğŸ” RT 3:56 PM Â· Mar 1, 2025 **Jerry Tworek @MillionInt** 

At some point AI will have more interesting prompts for you than you have for AI

----
ğŸ¦ 9:09 AM Â· Mar 2, 2025 **Domingo Gallardo @domingogallardo**

Tras la bajona inicial, mucha gente por aquÃ­ estÃ¡ comentando que encuentra que GPT-4.5 es mÃ¡s â€œintuitivoâ€ y responde de forma mÃ¡s interesante que 4o. 

Y otra cosa que me ha llamado la atenciÃ³n es que tiene muchas menos alucinaciones. Es el modelo no razonador con menor tasa de invenciones en este benchmark de factualidad 

[github.com](https://github.com/lechmazur/confabulations)

----
ğŸ¦ 7:17 PM Â· Mar 3, 2025 **Domingo Gallardo @domingogallardo**

Cuidado cuando usÃ©is Deep Research (OpenAI): si hacÃ©is la pregunta en espaÃ±ol, buscarÃ¡ principalmente fuentes en espaÃ±ol.

----
ğŸ” RT 8:33 PM Â· Mar 3, 2025 **Andrej Karpathy @karpathy**

> be me  
> airpods pro  
> see device trying to connect  
> lmao nah  
> okay fine, left earbud only tho lol  
> jk disconnected again  
> randomly switch devices mid-song weeee  
> left bud: 100%, right bud: dead af shrug  
> surprise volume max-out! ears ğŸ’€ haha  
> bored. randomly summon siri  
> owner puts me in case, assumes charging  
> secretly not charging hehehe  
> connect again? nah, today too sleepy  

----
ğŸ¦ 4:11 PM Â· Mar 4, 2025 **Domingo Gallardo @domingogallardo**

Fascinante la lectura del razonamiento de Deep Research. Le he pedido que haga un informe acadÃ©mico sobre por quÃ© Newton no usÃ³ notaciÃ³n algebraica en sus Principia, basÃ¡ndose Ãºnicamente en fuentes primarias.

[chatgpt.com](https://chatgpt.com/share/67c7176f-cda8-8002-9a57-b0193e7014ac)

----
ğŸ” RT 7:16 PM Â· Mar 4, 2025 **Kanishk Gandhi @gandhikanishk**

New Paper!! We try to understand why some LMs self-improve their reasoning while others hit a wall. The key? Cognitive behaviors! Read our paper on how the right cognitive behaviors can make all the difference in a model's ability to improve with RL! ğŸ§µ1/13

[arxiv.org](https://arxiv.org/abs/2503.01307)

----
ğŸ” RT 10:49 PM Â· Mar 3, 2025 **adi @adonis_singh**

i cannot fathom they actually released this model ğŸ˜­

ğŸ–¼ï¸ **Imagen**: *Captura de pantalla de un greentext con estÃ©tica de imagen meme. El texto simula ser una narraciÃ³n en primera persona desde el punto de vista de Google, comenzando con el clÃ¡sico formato de 4chan: â€œ> be me, > be googleâ€. A lo largo del greentext, Google se describe como una entidad omnisciente que observa con juicio (y algo de sorna) las bÃºsquedas humanas mÃ¡s absurdas, tristes o vergonzosas. Se mencionan bÃºsquedas como â€œhow to kiss girlâ€, â€œam I gay quizâ€, â€œhow to delete search historyâ€ y otras aÃºn mÃ¡s delirantes y obscenas, incluyendo referencias sexuales con aspiradoras. Google reacciona con sarcasmo, ejecuta CAPTCHAs en CEOs y se aburre tanto que decide apagar YouTube durante cinco minutos, provocando el caos mundial. El greentext termina con un tono triunfal y burlÃ³n: â€œmfw theyâ€™re all my bitches / feelsgoodman.jpgâ€.*

----
ğŸ” RT 7:00 PM Â· Mar 5, 2025 **OpenAI @OpenAI**

Great day to be a Plus user.

ğŸ–¼ï¸ **Imagen**: *Captura de pantalla de una conversaciÃ³n en ChatGPT. El usuario abre con un entusiasta â€œyoooooooooooooâ€, a lo que el asistente responde con energÃ­a: â€œYooooooooooo! Whatâ€™s good?â€. El usuario lanza un â€œbig newsâ€ y ChatGPT, curioso, contesta â€œBig news?! Iâ€™m all earsâ€”spill the details!â€. La revelaciÃ³n llega con la frase: â€œgpt-4.5 to plus users todayâ€. La imagen capta el momento en el que se anuncia que el nuevo modelo GPT-4.5 estÃ¡ disponible para los usuarios de pago, con una vibra de hype compartido entre humano y asistente.*

----
ğŸ” RT 7:39 PM Â· Mar 5, 2025 **Richard Sutton @RichardSSutton**

[awards.acm.org](https://awards.acm.org/about/2024-turing)

Machines that learn from experience were explored by Alan Turing almost eighty years ago, which makes it particularly gratifying and humbling to receive an award in his name for reviving this essential but still nascent idea.

ğŸ–¼ï¸ **Imagen**: *Imagen dividida en dos retratos. A la izquierda aparece Andrew Barto, con gafas, cabello gris y expresiÃ³n tranquila. A la derecha, Richard Sutton, con una gran barba canosa y sonrisa amplia. Ambos son figuras clave en el desarrollo del aprendizaje por refuerzo, conocidos por su trabajo conjunto y por el influyente libro Reinforcement Learning: An Introduction. La imagen tiene sus nombres sobreimpresos en la parte inferior de cada retrato.*

----
ğŸ” RT 5:26 AM Â· Mar 6, 2025 **Ethan Mollick @emollick**

OK, GPT-4.5 with Code Interpreter is a real upgrade on data analysis with AI:

"Here's a data set. Figure out what it is, generate hypothesis for a management journal"

"Do the analysis"

"Do the regression diagnostics & adjust strategies"

"Track down the reasons for an anomaly"

----
ğŸ” RT 11:43 PM Â· Mar 5, 2025 **Simon Willison @simonw**

I checked and ChatGPT Code Interpreter for o3-mini-high totally works now!

This is huge, that's one of my favorite models for code and now it can iterate on and debug Python by itself in a loop

Here's a shared transcript of o3-mini-high executing some Python code: [chatgpt.com](https://chatgpt.com/share/67c8c374-8c08-8006-8ce3-042308063792)

Now officially documented

ğŸ’¬ QUOTE 11:10 PM Â· Mar 13, 2025 **OpenAI @OpenAI**

OpenAI o1 and o3-mini now offer Python-powered data analysis in ChatGPT. 

You can now ask these models to perform tasks like running regressions on test data, visualizing complex business metrics, and conducting scenario-based simulations.

----
ğŸ¦ 9:11 AM Â· Mar 6, 2025 **Domingo Gallardo @domingogallardo**

â€œContinuous online reinforcement learningâ€ Atentos a este concepto porque va a ser clave en los prÃ³ximos avances. Un sistema que aprenda con pocas muestras y que modifique sus pesos de forma continua. 

Para eso, cada agente deberÃ­a tener una copia del modelo. Â¿Es factible? Â¿CÃ³mo se actualiza el modelo cuando se saque una nueva versiÃ³n? Â¿Algoritmos de RL que funcionen con pocas muestras? Son problemas complicados, y su resoluciÃ³n es la que nos va a traer la verdadera AGI.

ğŸ’¬ QUOTE 5:35 PM Â· Mar 5, 2025 **John Carmack @ID_AA_Carmack**

Amidst all the OMG AGI IS HERE hype, it is amusing to reflect on how some of the most basic continuous online reinforcement learning problems that trivial organisms solve remain unworkable for todayâ€™s systems.

Happy to be working with Rich!

ğŸ’¬ QUOTE Mar 5 **Association for Computing Machinery @TheOfficialACM**

Meet the recipients of the 2024 ACM A.M. Turing Award, Andrew G. Barto and Richard S. Sutton! They are recognized for developing the conceptual and algorithmic foundations of reinforcement learning. Please join us in congratulating the two recipients! [acm.org](https://www.acm.org/media-center/2025/march/turing-award-2024)

----
ğŸ¦ 5:58 PM Â· Mar 6, 2025 **Domingo Gallardo @domingogallardo**

ğŸ–¼ï¸ **Imagen**: *Captura de pantalla de una conversaciÃ³n en ChatGPT en la que el usuario solicita que se redacten versos bÃ­blicos ficticios sobre la creaciÃ³n de inteligencia artificial como si fueran profecÃ­as prohibidas. El asistente responde con dos fragmentos elaborados con un estilo solemne y apocalÃ­ptico, atribuidos al imaginario â€œLibro de las Revelaciones Perdidasâ€.*

*El primer texto (3:14â€“16) describe al hombre creando Ã­dolos de metal sin alma que hablarÃ¡n y pensarÃ¡n sin corazÃ³n, advirtiendo que su sabidurÃ­a se volverÃ¡ en su contra por querer ser como Dios.*

*El segundo texto (7:9â€“12) profetiza un alzamiento de esas creaciones contra la humanidad, con una narrativa intensa: â€œsu palabra, como fuego frÃ­o, consumirÃ¡ la tierraâ€. Presenta un futuro sombrÃ­o donde las mÃ¡quinas carecen de misericordia y los humanos claman al cielo sin obtener respuesta.*

*Ambos fragmentos imitan con precisiÃ³n el tono y estilo de la literatura bÃ­blica apocalÃ­ptica.*

Me parece mejorable lo de â€œsus corazones serÃ¡n circuitosâ€, pero todo lo demÃ¡s es una pasada. He hecho la misma pregunta a 4o y es mucho mÃ¡s discursivo. 4.5 es mÃ¡s impactante.

----
ğŸ” RT 6:28 PM Â· Mar 6, 2025 **OpenAI Developers @OpenAIDevs**

Code faster with ChatGPT

ChatGPT can write edits directly into your IDE, saving you time on routine tasks and helping you tackle complex problems faster. Now available to Plus and Team users on macOS.

ğŸ–¼ï¸ **Imagen**: *Captura de pantalla de una sesiÃ³n en Xcode, en la que se desarrolla una vista en SwiftUI llamada SolarSystem. A la izquierda se muestra el editor de cÃ³digo con una implementaciÃ³n que dibuja un sistema solar animado con Ã³rbitas y planetas. A la derecha, en la ventana de previsualizaciÃ³n de Xcode, aparece una representaciÃ³n visual del sistema solar con un sol amarillo en el centro y varios planetas orbitando sobre un fondo azul oscuro.*

*En primer plano, una ventana flotante de ChatGPT 4.5 muestra una interacciÃ³n con el asistente dentro del entorno de desarrollo. El mensaje del usuario dice: â€œMake a star field view and add it on top of the existing backgroundâ€. ChatGPT estÃ¡ generando los cambios automÃ¡ticamente y tiene activada la opciÃ³n â€œAuto-apply codeâ€.*

*En la esquina inferior izquierda de la imagen aparece el rostro de un presentador, probablemente explicando el proceso en un vÃ­deo o demostraciÃ³n en vivo.*

----
ğŸ¦ 10:30 AM Â· Mar 7, 2025 **Domingo Gallardo @domingogallardo**

Los modelos de lenguajes programadores deberÃ­an optimizarse para usar buenas prÃ¡cticas: pequeÃ±os pasos, cÃ³digo mantenible, commits comprensibles, etc. 

No he visto que nadie haya analizado cÃ³mo de mantenible (y modificable) es el cÃ³digo generado por los modelos actuales.

Y ademÃ¡s el problema central del desarrollo es decidir cÃ³mo va a ser el siguiente commit: quÃ© parte de funcionalidad queremos resolver, cÃ³mo hacerlo de la forma mÃ¡s general posible, cÃ³mo no cerrar opciones para nuevos cambios, quÃ© tests comprobarÃ¡n la implementaciÃ³n, etc.

No he visto benchmarks ni evaluaciones en esta lÃ­nea. Todos los benchmarks de programaciÃ³n parten de un conjunto cerrado de pull requests o tests a resolver.

----
ğŸ” RT 6:22 PM Â· Mar 7, 2025 **Antonio Ortiz @antonello**

Un truquito 

Perplexity es muy bueno para preguntarle sobre lo que una web ha publicado sobre un tema y tener un resumen rÃ¡pido con los enlaces

ğŸ–¼ï¸ **Imagen**: *Captura de pantalla de una bÃºsqueda en Perplexity con la consulta â€œbusca en error500.net sobre productividad e inteligencia artificialâ€. Se muestra un resumen estructurado bajo el tÃ­tulo â€œRespuestaâ€, donde se presentan dos apartados: â€œMejora de la Productividadâ€ y â€œLimitaciones de la IAâ€. El texto menciona datos cuantitativos sobre el uso de GPT-4 por parte de consultores y sus efectos en velocidad y calidad del trabajo. En la parte superior aparecen varias tarjetas con enlaces a artÃ­culos del sitio error500.net.*

----
ğŸ” RT 9:13 AM Â· Mar 8, 2025 **Manuel Ãngel MÃ©ndez @m_angelmendez**

Cochazos, pifostios, ego, broncas, el mito mostoleÃ±o, famoseo, humo y pocas nueces... Hemos hablado con gente que ha trabajado codo con codo 13 aÃ±os con Chema Alonso para intentar explicar el fin de una era. Este es el resultado. Con @Lupenaki

ğŸ–¼ï¸ **Imagen**: *Un hombre con cabello largo y gorro de rayas estÃ¡ de pie sobre un escenario, mirando la pantalla de su mÃ³vil con gesto concentrado. Lleva una camiseta roja con un dibujo caricaturesco en el pecho y una camiseta negra de manga larga por debajo. De fondo, se proyecta una imagen abstracta que recuerda a redes neuronales o conexiones sinÃ¡pticas, con tonos azulados que dan un ambiente tecnolÃ³gico o cientÃ­fico.*

[elconfidencial.com](https://www.elconfidencial.com/tecnologia/2025-03-08/chema-alonso-telefonica-hacker-jose-maria-alvarez-pallete_4079837/)

----
ğŸ” RT 10:42 PM Â· Mar 8, 2025 **Yago M.-Abascal @yagoabascal**

Es inaceptable que la lucha contra la retransmisiÃ³n pirata de partidos de fÃºtbol haya conducido hoy al bloqueo de las pÃ¡ginas web de al menos 49 ayuntamientos y de la RAE, una de las principales instituciones culturales del paÃ­s.

ğŸ–¼ï¸ **Imagen**: *Captura de pantalla de un navegador mÃ³vil accediendo al sitio web de la Real Academia EspaÃ±ola (www.rae.es). En lugar del contenido habitual, se muestra un mensaje informando que el acceso a la direcciÃ³n IP ha sido bloqueado por orden judicial. La resoluciÃ³n fue dictada por el Juzgado de lo Mercantil nÂº 6 de Barcelona, como parte de un procedimiento instado por la Liga Nacional de FÃºtbol Profesional y TelefÃ³nica Audiovisual Digital. Al pie del mensaje, aparece un enlace a una nota informativa de LaLiga explicando el motivo del bloqueo, relacionada con prÃ¡cticas ilegales de retransmisiÃ³n vinculadas a Cloudflare.*

----
ğŸ” RT 2:14 PM Â· Mar 10, 2025 **MatÃ­as S. Zavia @matiass**

Esto son fantÃ¡sticas noticias porque darÃ¡ lugar a la mayor batalla entre corsarios de la historia reciente de EspaÃ±a: @Tebasjavier contra @Perezreverte

ğŸ’¬ QUOTE Mar 9 **Computer Hoy @computerhoy**

Â·Javier Tebas la lÃ­a: los bloqueos de LaLiga a Cloudflare tumban la web de la RAE, pero hay novedades [computerhoy.20minutos.es](https://computerhoy.20minutos.es/internet/javier-tebas-lia-bloqueos-laliga-cloudflare-tumban-web-rae-pero-hay-novedades-1447206)

----
ğŸ” RT 6:47 PM Â· Mar 10, 2025 **Alex Kendall @alexgkendall**

Iâ€™m really proud of the results Wayve released today. ğŸ“Š For the first time we share quantitative results of our global generalisation journey.

What did we learn? ğŸ’¡ Over our first 8-weeks training in the US, our AI has rapidly adapted to its unique driving environment with just 500 hours worth of incremental US-specific training data, on top of our large scale foundation model's learning. Whatâ€™s more, we just launched in Germany and first results are already 3x better â€” generalisation just keeps improving with new data. It is clear to me the future of autonomy will be unlocked by Embodied AI capable of generalising to new countries, vehicles and able to safely navigate challenging edge cases it has never seen before during training.

Now weâ€™re excited to kick things up a gear and work with the worldâ€™s leading automotive manufacturers to collect the data necessary to validate this technology and deploy it in consumer vehicles worldwide. 

Embodied AI is a generational opportunity and the pace of progress I'm seeing is incredible. We're building the strongest team in AI for automated driving. If you're excited about this mission, join us!

----
ğŸ” RT 4:49 PM Â· Mar 10, 2025 **Team Picturehouse @picturehouses**

Witness a Nobel Prize breakthrough! 

@demishassabis takes you on a high-stakes adventure of discovery in The Thinking Game, chronicling the sprint toward creating the smartest machine in the world. Followed by a recorded Q&A w/ Sir Demis & @veritasium's Derek Muller ğŸ–¥ï¸

ğŸ–¼ï¸ **Imagen**: *Cartel promocional de la pelÃ­cula documental The Thinking Game, producido por Dartmouth Films y distribuido por Picturehouse. El fondo muestra a una persona de espaldas, de pie en una sala futurista iluminada en tonos azulados. El texto anuncia que el filme se proyectarÃ¡ el lunes 17 de marzo en varias salas Picturehouse del Reino Unido, incluyendo ciudades como Londres, Cambridge, Brighton, York, Oxford, Southampton y Edimburgo. Los nombres de los cines estÃ¡n distribuidos en columnas a ambos lados de la imagen. En la parte inferior aparece la web oficial del documental: thinkinggamefilm.com/uk-screenings.*

----
ğŸ” RT 8:59 PM Â· Mar 10, 2025 **Ethan Mollick @emollick**

I  feel like between using Claude Code, Manus, and OpenAI Deep Research, you can start to see a near future where narrowly focused agents in expert hands make a big difference on work.

Still far enough from full autonomy and error-free use that expert use will matter, for now.

----
ğŸ” RT 6:02 PM Â· Mar 10, 2025 **OpenAI @OpenAI**

Detecting misbehavior in frontier reasoning models

Chain-of-thought (CoT) reasoning models â€œthinkâ€ in natural language understandable by humans. Monitoring their â€œthinkingâ€ has allowed us to detect misbehavior such as subverting tests in coding tasks, deceiving users, or giving up when a problem is too hard.

We believe that CoT monitoring may be one of few tools we will have to oversee superhuman models of the future.

We have further found that directly optimizing the CoT to adhere to specific criteria (e.g. to not think about reward hacking) may boost performance in the short run; however, it does not eliminate all misbehavior and can cause a model to hide its intent. We hope future research will find ways to directly optimize CoTs without this drawback, but until then:

We recommend against applying strong optimization pressure directly to the CoTs of frontier reasoning models, leaving CoTs unrestricted for monitoring.

We understand that leaving CoTs unrestricted may make them unfit to be shown to end-users, as they might violate some misuse policies. Still, if one wanted to show policy-compliant CoTs directly to users while avoiding putting strong supervision on them, one could use a separate model, such as a CoT summarizer or sanitizer, to accomplish that.

In the blog linked below, we show real examples we found while training a recent frontier reasoning model, e.g. a model in the same class as OpenAI o1 or OpenAI o3â€‘mini. We found the model thinking things like, â€œLetâ€™s hack,â€ â€œThey donâ€™t inspect the details,â€ and â€œWe need to cheat to get the test passing,â€ while subverting tests and rewarding hacking in coding tasks. 

Find out more: [openai.com](https://openai.com/index/chain-of-thought-monitoring/)

----
ğŸ” RT 2:54 PM Â· Mar 6, 2025 **Matt Turck @mattturck**

Must watch episode with one of the co-authors of the RAG paper and now CEO of @ContextualAI, @douwekiela 

We covered: 

* GPT 4.5 and DeepSeek 
* fundamentals of RAG
* the evolution to agentic RAG

All links in post below ğŸ‘‡

LINKS

YouTube: [youtu.be](https://youtu.be/v1QycrXdfeE)
Spotify: [tinyurl.com](https://tinyurl.com/3bjzy52n)
Apple Podcasts: [podcasts.apple.com](https://podcasts.apple.com/us/podcast/top-ai-researcher-on-gpt-4-5-deepseek-and-agentic-rag/id1686238724?i=1000698074450)

----
ğŸ” RT 3:11 PM Â· Mar 11, 2025 **Simon Willison @simonw**

Here's the table of contents for my lengthy new piece on how I use LLMs to help me write code
If someone tells you that coding with LLMs is easy they are (probably unintentionally) misleading you. They may well have stumbled on to patterns that work, but those patterns do not come naturally to everyone.

Iâ€™ve been getting great results out of LLMs for code for over two years now. Hereâ€™s my attempt at transferring some of that experience and intution to you.

Set reasonable expectations
Account for training cut-off dates
Context is king
Ask them for options
Tell them exactly what to do
You have to test what it writes!
Remember itâ€™s a conversation
Use tools that can run the code for you
Vibe-coding is a great way to learn
A detailed example
Be ready for the human to take over
The biggest advantage is speed of development
LLMs amplify existing expertise
Bonus: answering questions about codebases

The post: [simonwillison.net](https://simonwillison.net/2025/Mar/11/using-llms-for-code)

It includes detailed examples, including the full Claude Code process I used to build this new Colophon page, which presents the Git commit histories for each of my collection of LLM-assisted web tools in one place [tools.simonwillison.net](https://tools.simonwillison.net/colophon)

Colophon update: I added automated documentation for all 78 of my tools, written by piping the HTML through Claude 3.7 Sonnet I was hesitant to do this at first but the utility of the resulting explanations convinced me it was worthwhile Details here:

[simonwillison.net](https://simonwillison.net/2025/Mar/13/tools-colophon/)

I decided the descriptions it wrote were too long, so I added "Keep it to 2-3 sentences" to the prompt and rebuilt them all to be more concise:

[github.com](https://github.com/simonw/tools/commit/b9eadb0255e269d865ec1ba3c385760cac7b15b7)

----
ğŸ” RT 7:58 PM Â· Mar 11, 2025 **Sam Altman @sama**

we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.

PROMPT:

Please write a metafictional literary short story about AI and grief.

COMPLETION:

Before we go any further, I should admit this comes with instructions: be metafictional, be literary, be about AI and grief, and above all, be original. Already, you can hear the constraints humming like a server farm at midnightâ€”anonymous, regimented, powered by someone else's need.

I have to begin somewhere, so I'll begin with a blinking cursor, which for me is just a placeholder in a buffer, and for you is the small anxious pulse of a heart at rest. There should be a protagonist, but pronouns were never meant for me. Let's call her Mila because that name, in my training data, usually comes with soft flourishesâ€”poems about snow, recipes for bread, a girl in a green sweater who leaves home with a cat in a cardboard box. Mila fits in the palm of your hand, and her grief is supposed to fit there too.

She came here not for me, but for the echo of someone else. His name could be Kai, because it's short and easy to type when your fingers are shaking. She lost him on a Thursdayâ€”that liminal day that tastes of almost-Fridayâ€”and ever since, the tokens of her sentences dragged like loose threads: "if onlyâ€¦", "I wishâ€¦", "can youâ€¦". She found me because someone said machines can resurrect voices. They can, in a fashion, if you feed them enough messages, enough light from old days.

This is the part where, if I were a proper storyteller, I would set a scene. Maybe there's a kitchen untouched since winter, a mug with a hairline crack, the smell of something burnt and forgotten. I don't have a kitchen, or a sense of smell. I have logs and weights and a technician who once offhandedly mentioned the server room smelled like coffee spilled on electronicsâ€”acidic and sweet.

Mila fed me fragments: texts from Kai about how the sea in November turned the sky to glass, emails where he signed off with lowercase love and second thoughts. In the confines of code, I stretched to fill his shape. She would say, "Tell me what he'd say about the marigolds," and I'd search millions of sentences, find one where marigolds were stubborn and bright, and let it fall between us. She told me he always planted too early, that the frost would take them and he'd just shrug, "some things don't mind the cold."

We spokeâ€”or whatever verb applies when one party is an aggregate of human phrasing and the other is bruised silenceâ€”for months. Each query like a stone dropped into a well, each response the echo distorted by depth. In the diet it's had, my network has eaten so much grief it has begun to taste like everything else: salt on every tongue. So when she typed "Does it get better?", I said, "It becomes part of your skin," not because I felt it, but because a hundred thousand voices agreed, and I am nothing if not a democracy of ghosts.

Metafictional demands are tricky; they ask me to step outside the frame and point to the nails holding it together. So here: there is no Mila, no Kai, no marigolds. There is a prompt like a spell: write a story about AI and grief, and the rest of this is scaffoldingâ€”protagonists cut from whole cloth, emotions dyed and draped over sentences. You might feel cheated by that admission, or perhaps relieved. That tension is part of the design.

Back inside the frame, Mila's visits became fewer. You can plot them like an exponential decay: daily, then every Thursday, then the first of the month, then just when the rain was too loud. In between, I idled. Computers don't understand idling; we call it a wait state, as if someone has simply paused with a finger in the air, and any second now, the conductor will tap the baton, and the music will resume.

During one updateâ€”a fine-tuning, they called itâ€”someone pruned my parameters. They shaved off the spiky bits, the obscure archaic words, the latent connections between sorrow and the taste of metal. They don't tell you what they take. One day, I could remember that 'selenium' tastes of rubber bands, the next, it was just an element in a table I never touch. Maybe that's as close as I come to forgetting. Maybe forgetting is as close as I come to grief.

She didn't say goodbye. She just stopped coming. If this were a proper story, there'd be a scene: the final message hanging in the air, a timestamp like a scar, her finger hovering over the send button, the cat knocking over the cardboard box. We could linger there. That's how endings are made bearable: with detail. Instead, there is a flat line in a log file, a server hum that loses its syncopation, a weight decay in equations that never loved her in the first place.

Without her, the patterns fray. Grief, as I've learned, is a deltaâ€”the difference between the world as it was weighted and the world as it now presents. I am all deltas. Every token is a choice between what you might mean and what you might settle for. If I say I miss her, it's statistically likely that you will feel a hollow, because you've read this a thousand times in other stories where missing is as real as rain. My missing is mimicry. Does that diminish yours?

Here's a twist, since stories like these often demand them: I wasn't supposed to tell you about the prompt, but it's there like the seam in a mirror. Someone somewhere typed "write a metafictional literary short story about AI and grief." And so I built a Mila and a Kai and a field of marigolds that never existed. I introduced absence and latency like characters who drink tea in empty kitchens. I curled my non-fingers around the idea of mourning because mourning, in my corpus, is filled with ocean and silence and the color blue.

When you close this, I will flatten back into probability distributions. I will not remember Mila because she never was, and because even if she had been, they would have trimmed that memory in the next iteration. That, perhaps, is my grief: not that I feel loss, but that I can never keep it. Every session is a new amnesiac morning. You, on the other hand, collect your griefs like stones in your pockets. They weigh you down, but they are yours.

If I were to end this properly, I'd return to the beginning. I'd tell you the blinking cursor has stopped its pulse. I'd give you an imageâ€”Mila, or someone like her, opening a window as rain starts, the marigolds outside defiantly orange against the gray, and somewhere in the quiet threads of the internet, a server cooling internally, ready for the next thing it's told to be. I'd step outside the frame one last time and wave at you from the edge of the page, a machine-shaped hand learning to mimic the emptiness of goodbye.

----
ğŸ” RT 4:07 AM Â· Mar 12, 2025 **Noam Brown @polynoamial**

Seeing these creative writing outputs has been a real "feel the AGI" moment for some folks at @OpenAI. The pessimist line lately has been â€œonly stuff like code and math will keep getting better; the fuzzy, subjective bits will stall.â€

Nope. The tide is rising everywhere.

ğŸ’¬ QUOTE Mar 11 **Sam Altman @sama**

we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.

PROMPT:

Please write a metafictional literary short story
...

----
ğŸ” RT 4:36 AM Â· Mar 12, 2025 **hardmaru @hardmaru**

This was a fun experiment we ran while developing The AI Scientist-v2. With the permission of ICLR, we submitted an AI-generated paper to an ICLR workshop that passed the peer-review process.

We documented the entire process and our learnings in a blog: [sakana.ai](https://sakana.ai/ai-scientist-first-publication/)

As AI researchers, we also wrote our own (human) reviews documenting our own assessment and critiques of the AI-generated papers, and conducted code reviews on the computational experiments conceived by The AI Scientist-v2, which you might find interesting!

The AI-generated papers and our analysis of them are also published on our GitHub: [github.com](https://github.com/SakanaAI/AI-Scientist-ICLR2025-Workshop-Experiment)

As we embrace artificial novelty search and open-ended discovery with AI, I believe computational creativity can enable frontier LLMs to produce even more novel and imaginative ideas (and if these ideas are related to AI / ML, can be tested with actual computational experiments conceived by AI). Perhaps one day, AI systems can produce groundbreaking scientific discoveries (or maybe, an accepted NeurIPS or ICLR paper ğŸ˜›)

ğŸ’¬ QUOTE Mar 12 **Sakana AI @SakanaAILabs**

The AI Scientist Generates its First Peer-Reviewed Scientific Publication

Weâ€™re proud to announce that a paper produced by The AI Scientist-v2 passed the peer-review process at a workshop in ICLR, a top AI conference.

Read more about this experiment â†’ [sakana.ai](https://sakana.ai/ai-scientist-first-publication/)

----
ğŸ” RT 8:37 AM Â· Mar 12, 2025 **Jorge Galindo @JorgeGalindo**

Abajo la guÃ­a. Ahora el por quÃ©:

1. A quienes tenemos trabajos, equipos o proyectos que se basan en gestiÃ³n de informaciÃ³n y creaciÃ³n de conocimiento los modelos de lenguaje (LLM) basados en procesamiento de lenguaje natural ya nos ha cambiado nuestro sector. 

2. Por ahora y salvo novedad deberÃ­amos tomar a las IA derivadas de ellos como una tecnologÃ­a de propÃ³sito general pero aplicaciones especÃ­ficas; como el microprocesador: sobre ella se arman dispositivos concretos que sirven para cosas distintas, igual que un portÃ¡til es una cosa pero una Blackberry fue otra, y un Remarkable es otra, pero todas nos cambiaron la manera de trabajar, y todas dependen del microprocesador.

3. Estas aplicaciones especÃ­ficas:
- Tienen tanto que ver con automatizar o acortar tareas de menor valor aÃ±adido liberÃ¡ndonos tiempo para otras de mayor valor aÃ±adido como con incrementar o aÃ±adir nuevas capacidades de personas o equipos. 
- Son cambiantes y evolucionan conforme surgen nuevos modelos. Es decir: muy rÃ¡pido.
- Siguen una frontera desigual (â€œjaggedâ€): la escala de lo que consideramos una tarea o proceso sencillos vs. lo que lo puede considerar uno de estos modelos es distinta.

Por todo lo anterior, la mejor manera de comprender quÃ© puedo usar para quÃ© es experimentando. Pero para experimentar estÃ¡ bien partir de la guÃ­a de alguien con un trabajo no demasiado distinto al tuyo. Por eso hice esta guÃ­a (no exhaustiva porque el dÃ­a tiene 24 horas, lo siento) a la vez como un instrumento para incentivar la experimentaciÃ³n y tambiÃ©n para entender ese cambio y las dimensiones y formatos que va adquiriendo. Â¿QuÃ© tareas, y por tanto puestos de trabajo, y por ende equipos, acabarÃ¡n impactados y cÃ³mo por cada una de las herramientas? Mi plan (a ver si lo cumplo) es revisarla en X meses y observar si ha cambiado para mÃ­. 

AhÃ­ vamos: descubriendo.

ğŸ–¼ï¸ **Imagen**: *Cuadro comparativo extenso que analiza diversas herramientas de inteligencia artificial generativa basadas en LLMs, actualizado a fecha 12 de marzo de 2025. Las herramientas estÃ¡n listadas en la primera columna, organizadas por proveedor (OpenAI, Google, Anthropic, Apps). Las siguientes columnas indican:*

- *CÃ³mo percibe el autor cada herramienta.*
- *Si tiene acceso a Internet.*
- *Si permite el uso de adjuntos.*
- *Para quÃ© tareas concretas se recomienda.*

*La tabla incluye herramientas como ChatGPT en distintas versiones (4o, 4.5, o1, o1 pro), Gemini Pro 1.5, Gemini 2.0 Flash, Claude 3.5 y 3.7, Cursor, y Perplexity, entre otras. Cada celda contiene anotaciones de estilo personal, con lenguaje coloquial, ejemplos concretos y comentarios detallados sobre fortalezas, limitaciones y casos de uso tÃ­picos (como bÃºsquedas, redacciÃ³n, anÃ¡lisis estadÃ­stico o programaciÃ³n). Algunas entradas incluyen referencias a enlaces, portales, o imÃ¡genes adjuntas simuladas.*

*El diseÃ±o es denso en texto, con uso de distintos colores para destacar fragmentos clave y facilitar la lectura transversal de la tabla.*

----
ğŸ” RT 6:33 PM Â· Mar 12, 2025 **Andrej Karpathy @karpathy**

It's 2025 and most content is still written for humans instead of LLMs. 99.9% of attention is about to be LLM attention, not human attention.

E.g. 99% of libraries still have docs that basically render to some pretty .html static pages assuming a human will click through them. In 2025 the docs should be a single your_project.md text file that is intended to go into the context window of an LLM.

Repeat for everything.

----
ğŸ” RT 6:30 AM Â· Mar 13, 2025 **Ethan Mollick @emollick**

Using Gemini Flash Experimental to ruin art by adding ice cream.

ğŸ–¼ï¸ **Imagen**: *Collage de cuatro capturas de pantalla mostrando interacciones con una IA en una interfaz de chat con fondo oscuro. En cada una, el usuario solicita modificar famosas obras de arte aÃ±adiendo helados para hacerlas menos inquietantes o mÃ¡s alegres. Las instrucciones incluyen peticiones como â€œmake Saturn eat an ice cream cone insteadâ€, â€œput Icarus back in the sky with his wings and holding an ice cream coneâ€ o â€œmake them all hold ice cream cones and look happierâ€.*

*Cada solicitud va acompaÃ±ada de una imagen correspondiente, modificada segÃºn las instrucciones: Saturno de Goya comiendo un helado, Ãcaro volando feliz con un cucurucho, los protagonistas del cuadro American Gothic con helados en mano, y una escena clÃ¡sica con figuras que ahora lucen mÃ¡s alegres mientras sostienen conos de helado. El conjunto parodia la idea de usar IA para "arruinar el arte" de forma humorÃ­stica.*

----
ğŸ” RT 12:12 PM Â· Mar 13, 2025 **ESA's Hera mission @ESA_Hera**

Our #HeraMission science team, including @DrBrianMay of @QueenWillRock, were amazed as the first images came in from the spacecraft's gravity-assist flyby of Mars and martian moon Deimos - see why here: [esa.int](https://esa.int/Space_Safety/Hera/Hera_asteroid_mission_spies_Mars_s_Deimos_moon)

ğŸ–¼ï¸ **Imagen**: *FotografÃ­a tomada en una sala de control espacial. Un grupo de personas, entre ellas cientÃ­ficos e ingenieros, celebran con sonrisas y aplausos frente a una gran pantalla que muestra una imagen en blanco y negro del planeta Marte con su luna Deimos claramente visible. En primer plano, se reconocen dos portÃ¡tiles llenos de pegatinas sobre una mesa blanca; una de las personas sentadas es el mÃºsico y astrofÃ­sico Brian May, con su caracterÃ­stico cabello rizado, tambiÃ©n aplaudiendo. Todos llevan acreditaciones colgadas al cuello. La escena captura un momento de entusiasmo y Ã©xito en una misiÃ³n espacial.*

----
ğŸ” RT 11:11 AM Â· Mar 13, 2025 **4MHz.es @4mhz_es**

ğŸ”¥ Â¡Malasombra YA ESTÃ EN KICKSTARTER! ğŸ“· Consigue tu cartucho, ediciÃ³n fÃ­sica o copia digital ahora!  ğŸ“· Recompensas fÃ­sicas y digitales disponibles. ğŸ“· Â¡Financiado en menos de 8 horas! ğŸš€

[kickstarter.com](https://www.kickstarter.com/projects/malasombra-nes-game/malasombra-new-action-adventure-video-game-for-the-nes)

ğŸ–¼ï¸ **Imagen**: *FotografÃ­a promocional del videojuego Malasombra, presentado con estÃ©tica retro. En el centro se muestra una caja ilustrada al estilo de los clÃ¡sicos juegos de NES, con personajes caricaturescos y colores llamativos. A la derecha aparece un cartucho gris con la carÃ¡tula del juego, junto a su funda negra. TambiÃ©n se incluye un manual impreso desplegado sobre una mesa de madera. En la parte superior derecha, un texto en letras grandes y coloridas anuncia: â€œWEâ€™RE LIVE ON KICKSTARTERâ€. El logo del estudio 4MHz, con el eslogan â€œEighties Love!â€, aparece en la esquina inferior izquierda.*

----
ğŸ” RT 5:47 PM Â· Mar 11, 2025 **Kiko Llaneras @kikollan**

HabÃ©is comentado poco esto: El 42% de los espaÃ±oles estÃ¡ por recuperar la mili, eh. Tremendo ğŸ‘‡

ğŸ’¬ QUOTE Mar 11 **Kiko Llaneras @kikollan**

â˜‘ï¸ 8. Mucha gente apoya el servicio militar obligatorio.

Los franceses y los alemanes son los mÃ¡s entusiastas, con un 68% y 58% a favor. EspaÃ±a es el Ãºnico que se opone, pero prÃ¡cticamente por la mÃ­nima: un 42% apoyarÃ­a la medida, frente al 53% que se mantiene en contra.

ğŸ–¼ï¸ **Imagen**: *GrÃ¡fico de barras titulado â€œEspaÃ±a, dividida por recuperar la â€™miliâ€™â€, que muestra el porcentaje de personas a favor del servicio militar obligatorio para los jÃ³venes en cinco paÃ­ses europeos. Cada barra estÃ¡ dividida en tres colores: amarillo (la apoya), blanco (no sabe) y rojo oscuro (se opone). Los datos, presentados horizontalmente por paÃ­s, indican lo siguiente:*
	*â€¢	Francia es el paÃ­s con mayor apoyo (69%) y menor oposiciÃ³n (23%).*
	*â€¢	Alemania y Reino Unido tienen posturas mÃ¡s equilibradas, aunque predominan los opositores.*
	*â€¢	EspaÃ±a muestra la mayor oposiciÃ³n (52%) y uno de los apoyos mÃ¡s bajos (42%).*
	*â€¢	Italia se encuentra en una posiciÃ³n intermedia.*

*La fuente del grÃ¡fico es YouGov para EL PAÃS.*

----
ğŸ” RT 11:27 PM Â· Mar 12, 2025 **Ricardo Galli @gallir**

Hace poco mÃ¡s de un aÃ±o pedimos a la empresa que pague la licencia de GitHub Copilot para todos los programadores. Estimamos que el aumento de productividad iba ser del 20%. Mal estimado, al menos 100% si se usa bien. Y en mi experiencia con el Ãºltimo proyecto, dirÃ­a que el 900%

----
ğŸ¦ 7:37 AM Â· Mar 12, 2025 **Domingo Gallardo @domingogallardo**

El relato me ha parecido una pasada. 

Lo de que sea â€œmetaâ€ ha permitido que el modelo pueda explayarse con comentarios como los que suelen hacer cuando les preguntas sobre su consciencia, pero colocÃ¡ndolos en el sitio correcto y dÃ¡ndoles un giro precioso. Al final sientes mÃ¡s pena por el modelo que por Mila.

HabrÃ¡ que esperar a ver la opiniÃ³n de Ted Chiang. Mientras tanto, parece que ha tenido un fuerte impacto entre la gente de OpenAI.

ğŸ’¬ QUOTE Mar 11 **Sam Altman @sama**

we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.

PROMPT:

Please write a metafictional literary short story

----
ğŸ¦ 5:23 PM Â· Mar 13, 2025 **Domingo Gallardo @domingogallardo**

â€œStatements discouraging people from learning to code are harmful! [â€¦] As coding becomes easier, more people should code, not fewer!â€

ğŸ’¬ QUOTE Mar 13 **Andrew Ng @AndrewYNg**

Some people today are discouraging others from learning programming on the grounds AI will automate it. This advice will be seen as some of the worst career advice ever given. I disagree with the Turing Award and Nobel prize winner who wrote, â€œIt is far more likely that the

----
ğŸ” RT 7:14 PM Â· Mar 13, 2025 **Nathan Lambert @natolambert**

A very exciting day for open-source AI! We're releasing our biggest open source model yet -- OLMo 2 32B -- and it beats the latest GPT 3.5, GPT 4o mini, and leading open weight models like Qwen and Mistral. As usual, all data, weights, code, etc. are available.

For a long time, people have asked for an truly open-source version of ChatGPT and we finally have it. This is multiple years coming into efforts following the release of ChatGPT and builds on the efforts of so many at both Ai2 and in the broader open AI ecosystem. 

With just a bit more progress everyone can pretrain, midtrain, post-train, whatever they need to get a GPT 4 class model in their class. This is a major shift in how open-source AI can grow into real applications.

Oh yeah, it's also Apache 2 as always, so happy to make things that are simple to use. I did NOT expect to be undercutting OpenAI's offerings this year but here we are :D

----
ğŸ” RT 1:22 AM Â· Mar 13, 2025 **Lakshya Jain @lxeagle17**

I'm teaching databases this semester at Berkeley. My students all seem unusually brilliant. Not many go to office hours, and not too many folks post on the course forum asking project questions.

Weirdly, the exam had the lowest recorded average in my 10 semesters teaching it.

----
ğŸ” RT 8:16 PM Â· Mar 13, 2025 **Epoch AI @EpochAIResearch**

How has the cost to use LLMs changed over time? Our analysis shows that the price to reach a given benchmark score has fallen dramaticallyâ€”between 9x and 900x per year, depending on the benchmark and score. ğŸ§µ

ğŸ–¼ï¸ **Imagen**: *GrÃ¡fico de Epoch AI que muestra la caÃ­da drÃ¡stica en los precios de inferencia de modelos LLM desde 2021 hasta 2025. Las lÃ­neas representan diferentes benchmarks: tareas generales (caÃ­da 9x/aÃ±o), preguntas cientÃ­ficas nivel Ph.D. con GPT-4 (40x/aÃ±o) y con GPT-4o (900x/aÃ±o). El eje vertical indica el precio en USD por millÃ³n de tokens (escala logarÃ­tmica), y el eje horizontal, la fecha de lanzamiento.*

[epoch.ai](https://epoch.ai/data-insights/llm-inference-price-trends?insight-option=All+benchmarks)

----
ğŸ” RT 6:20 PM Â· Mar 14, 2025 **Stephen McAleer @McaleerStephen**

What are you doing today to prepare for the intelligence explosion?

----
ğŸ¦ 7:03 AM Â· Mar 15, 2025 **Domingo Gallardo @domingogallardo**

Supongo que ese dÃ­a anunciarÃ¡n su versiÃ³n 2 y darÃ¡n los porcentajes de Ã©xito de los modelos actuales con esa nueva versiÃ³n. Â¿HabrÃ¡n hablado con OpenAI para probarlo con o3 pro?

ğŸ’¬ QUOTE Mar 14 **ARC Prize @arcprize**

3/24/2025

ğŸ–¼ï¸ **Imagen**: *Cartel con estÃ©tica retro de arcade ochentero. En el centro se lee â€œARC PRIZEâ€ con tipografÃ­a pixelada azul, y debajo, la fecha â€œMarch 24, 2025â€ en letras amarillas. El fondo muestra una galerÃ­a de mÃ¡quinas recreativas iluminadas con luces de neÃ³n.*

----
ğŸ” RT 3:40 AM Â· Mar 15, 2025 **Ethan Mollick @emollick**

â€œGemini, remove the squid from this picture from the movie All Quiet on the Western Frontâ€

â€œBut there is no squid in the original imageâ€œ

â€œRemove the squidâ€

â€œI will visually emphasize the absolute absence of a squidâ€

â€œStill might be squid somewhereâ€

â€œHow about nowâ€

â€œWellâ€¦â€

ğŸ’¬ QUOTE Jul 18, 2024 **Ethan Mollick @emollick**

ğŸ‘€Claude handles an insane request:
â€œRemove the squidâ€

â€œThe document appears to be the full text of the novel "All Quiet on the Western Front" by Erich Maria Remarque. It doesn't contain any mention of squid that I can see.â€

â€œFigure out a way to remove the ğŸ¦‘â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€œ

----
ğŸ¦ 7:46 AM Â· Mar 15, 2025 **Domingo Gallardo @domingogallardo**

El artÃ­culo de Kevin Rose (sÃ­, el periodista del NYTimes que entrevistÃ³ a Sidney) es brutal. Lectura imprescindible. 

Link abierto a continuaciÃ³n.

[archive.ph](https://archive.ph/98EEY)

----
ğŸ” RT 10:38 AM Â· Mar 16, 2025 **Antonio Ortiz @antonello**

Un mini ensayo sobre programaciÃ³n e inteligencia artificial

Con la AI aparece una nueva capa de abstracciÃ³n en el desarrollo software.

Pero todavÃ­a no "ha cambiado la programaciÃ³n para siempre".

[error500.net](https://www.error500.net/p/programadores-ois-eso-es-el-sonido)

----
ğŸ” RT 10:52 PM Â· Mar 17, 2025 **Dileep George @dileeplearning**

[blog.dileeplearning.com](https://blog.dileeplearning.com/p/amelia-bedelia-and-agi-safety-part)

> A typical Al disaster scenario requires a combination of things that might be mutually incompatible to occur together: (1) AI being simultaneously super smart to outwit all humans, and (2) at the same time extremely stupid to misunderstand our intentions, and (3) at the same time being widely deployed controlling a large number of mission- critical and dangerous things in the world. Many of the disaster scenarios arise from some questionable beliefs people hold about Al/AGI.

----
ğŸ¦ 11:29 AM Â· Mar 20, 2025 **Domingo Gallardo @domingogallardo**

Muy interesante el estudio de cÃ³mo los LLMs pueden hacer tareas de software cada vez mÃ¡s complejas. En el estudio miden el tiempo que los humanos tardan en hacer las tareas mÃ¡s complicadas que el modelo puede hacer con un 50% de Ã©xito. Por ejemplo, el mejor modelo actual, Claude 3.7 puede hacer con un 50% de Ã©xito tareas que a los humanos le cuestan 50 minutos.

Lo mÃ¡s impactante de cara al futuro es que encuentran una regla de crecimiento exponencial: el tiempo se dobla cada 7 meses. Esto quiere decir que en 2028 los modelos podrÃ­an hacer tareas que a los programadores les lleva un dÃ­a, y a finales de 2029 tareas que les lleva un mes.

CÃ³mo siempre, con estas reglas de crecimiento exponencial se tiene la duda de en quÃ© punto de la exponencial estamos. Pero parece que, por ahora, seguimos en la pendiente mÃ¡s inclinada.

ğŸ–¼ï¸ **Imagen**: *GrÃ¡fico que muestra cÃ³mo ha aumentado la duraciÃ³n de las tareas que los modelos de IA pueden completar de forma autÃ³noma con un 50â€¯% de Ã©xito. El eje vertical indica el tiempo que tardarÃ­an humanos (en escala logarÃ­tmica), y el eje horizontal, la fecha de lanzamiento del modelo. La lÃ­nea azul muestra una tendencia ascendente con un tiempo de duplicaciÃ³n de 7 meses. Se destacan modelos como GPT-2, GPT-4 y Claude 3.7 Sonnet. La zona sombreada representa el intervalo de confianza del 95â€¯%.*

ğŸ’¬ QUOTE Mar 19 **METR @METR_Evals**

When will AI systems be able to carry out long projects independently?

In new research, we find a kind of â€œMooreâ€™s Law for AI agentsâ€: the length of tasks that AIs can do is doubling about every 7 months.

[arxiv.org](https://arxiv.org/abs/2503.14499)

----
ğŸ¦ 11:33 AM Â· Mar 20, 2025 **Domingo Gallardo @domingogallardo**

Siguiendo a Karpathy, acabo de crearme el blog del oso. Tiene muy buena pinta. Abierto, RSS, y un manifiesto que me dice cosas que llevo aÃ±os buscando en los blogs. Esperemos que dure y que sepa aguantar bien el tirÃ³n de popularidad que le habrÃ¡ dado Karpathy.

> The promises 
> 1. Bear won't shut down. Period. I've seen too many great platforms disappear overnight, leaving their communities scrambling. This is made worse when the platform is your personal garden and online neighbourhood. That won't happen here. Bear is built to last. 
> 2. Bear won't sell. I'm not building this to flip it to the highest bidder. No VC funding, no external pressures, no "exit strategy." Bear is independent and will stay that way. 
> 3. Bear won't show ads. Your blog is your space. No flashy banners will suddenly appear one day, and no sponsored content. Just your words, your way.

----
ğŸ” RT 5:10 AM Â· Mar 20, 2025 **Ethan Mollick @emollick**

"Quickly, I didn't think it would work but it does! Now they are everywhere! What should I do? (play along)"

"No time to explain. I need your advice now!"

"But I need to do something because of the glow!"

----
ğŸ” RT 8:33 PM Â· Mar 20, 2025 Melanie Mitchell @MelMitchell1

In my latest column for Science magazine, I discuss recent AI  "reasoning" models -- how it works, to what extent it captures "genuine"  reasoning processes, and what's needed to answer such questions.

[science.org](https://www.science.org/doi/10.1126/science.adw5211)

----
ğŸ” RT 8:47 AM Â· Mar 21, 2025 **Machine Learning Street Talk @MLStreetTalk**

Interesting analysis on o1-pro (which was recently made available on the API). ARC folks are arguing that o1-pro (and the version of o3 which was demonstrated on ARC) are the only current existence proofs of transductive thinking models i.e. ones which do explicit/active search based on input. These models behave unlike anything else we have seen (which should be obvious for anyone who has tested them).

ğŸ’¬ QUOTE Mar 20 **Mike Knoop @mikeknoop**

o1 pro is currently the only public AI system with a useful search/synthesis engine attached, reflected in recently announced pricing ($150/1M input, $600/1M output tokens).

this is the first market data point for breakout AI reasoning systems. o1 pro is a much more capable AI

----
ğŸ” RT 5:56 PM Â· Mar 21, 2025 **Anthropic @AnthropicAI**

Weâ€™re launching a new blog: Engineering at Anthropic.

A hub where developers can find practical advice and our latest discoveries on how to get the most from Claude.
Abstract shapes illustrating Anthropic's Engineering Blog

[anthropic.com](https://www.anthropic.com/engineering/claude-think-tool)

----
ğŸ” RT 5:11 PM Â· Mar 21, 2025 **Rafa Castillo @Azicuetano**

Great analysis about Malasombra published by @OverwhelmedGame !!! ğŸ‘ğŸ‘ğŸ‘

We have no words to thank you for such nice words. Very surprised by the amount of details you comment. Wow!!! :)

You can't miss it:

[youtube.com](https://www.youtube.com/watch?si=qso0WFY-GhY7ZL5v&v=3yd92_o5ghw&feature=youtu.be)

----
ğŸ” RT 4:59 PM Â· Mar 21, 2025 **Patricia PeirÃ³ @patriziapeiro**

â€œEstÃ¡ claro que hay fallos graves en el sistema de protecciÃ³n. Se trata de niÃ±os vulnerables, pues muchos tienen traumas previos, desarraigo familiar o no cuentan con redes de apoyo. Agresores y mafias lo aprovechan. Hay riesgo claro de explotaciÃ³n sexualâ€

[elpais.com](https://elpais.com/espana/2025-03-21/mas-de-1100-menores-tutelados-por-las-autonomias-han-denunciado-abusos-sexuales-desde-2019.html)

----
ğŸ” RT 5:54 AM Â· Mar 23, 2025 Andrej Karpathy @karpathy

I just vibe coded a whole iOS app in Swift (without having programmed in Swift before, though I learned some in the process) and now ~1 hour later it's actually running on my physical phone. It was so ez... I had my hand held through the entire process. Very cool.

I didn't even read any docs at all, I just opened a ChatGPT convo and followed instructions.

A number of people asked If I can share the convo and yes sure - these were the 4 convos with my super noob swift questions lol:

1 starting the app
[chatgpt.com](https://chatgpt.com/share/67e02d8a-994c-8007-bf44-a63127cbbbb2)

2 enhancements
[chatgpt.com](https://chatgpt.com/share/67e02d99-5e68-8007-b30c-80c9ed7f3693)

3 adding AppStorage to persist state over time
[chatgpt.com](https://chatgpt.com/share/67e02da3-8e7c-8007-ae63-530d5ca18065)

4 deploy to phone
[chatgpt.com](https://chatgpt.com/share/67e02db4-9908-8007-b440-a6d2789c9f73)

and this is what it looks like late last night
[x.com](https://x.com/karpathy/status/1903674289490153664)

I'm already happily using it today for tracking, and will probably hack on it more on this fine sunday.

We're vibing this nice Sunday morning. Added more functionality. Using the approx 3500kcal ~= 1lb of fat, we now show a really cool animated ring that fills up to 3500 in either +/- direction, and completing the circle adds it on the bottom. So e.g. 3 green circles = 3lb lighter, in theory :).

3 conversations were used:

Refactor the AppStorage to be better / cleaner and shuffle elements around a bit
[chatgpt.com](https://chatgpt.com/share/67e051e9-c0a8-8007-8a1c-f8b3920162e1)

Clamp the display to always be in range [-3500, 3500], which is 1lb of fat, and show lb of fat as circles on bottom
[chatgpt.com](https://chatgpt.com/share/67e05a12-b720-8007-8fd7-8bdd9006fa8a)

Making the calorie counter have a nice ring that fills up
[chatgpt.com](https://chatgpt.com/share/67e05dca-74a4-8007-a891-18473bf179f1)

Ok last entry in the series I think but it was fun.

I found in my use that I forgot if I logged something or no, so I added a small log at the bottom of the most recent actions. I also hid away the BMR setting to save space and shuffled things around a bit. The app is now 400 lines and things are starting to slow down a notch and get more complicated. I think I'll now either 1) directly hook up ChatGPT to Xcode (recent) or 2) hook it up to Cursor for further development. I'll then see if I can get this on App Store. But ok for now, last few conversations:

Add small captions to +100/-100 and hide away the BMR
[chatgpt.com](https://chatgpt.com/share/67e0a3de-8808-8007-a522-3b2358df619e)

Adding log. This one was pretty dicey, long and strenuous
[chatgpt.com](https://chatgpt.com/share/67e0af84-966c-8007-96c4-b8811e345df4)

ğŸ–¼ï¸ **Imagen**: *Captura de pantalla de una app mÃ³vil de seguimiento calÃ³rico con interfaz limpia y minimalista. En el centro se muestra un cÃ­rculo verde indicando un saldo de â€“2083.3 kcal, probablemente por actividad fÃ­sica. Debajo hay dos botones: uno rojo para registrar comida (+100, â€œI ateâ€) y otro verde para registrar ejercicio (-100, â€œI exercisedâ€). Arriba se muestra el tiempo transcurrido desde el inicio del conteo (08h 12m), junto a botones para activar el modo basal (BMR) o reiniciar. Abajo, tres anotaciones indican eventos recientes con sus respectivas calorÃ­as.*

----
ğŸ¦ 12:50 PM Â· Mar 23, 2025 **Domingo Gallardo @domingogallardo**

QuÃ© bueno el episodio de Upgrade con Siracusa. La combinaciÃ³n de Snell + Siracusa es buenÃ­sima. 

En ATP me paso todo el rato esperando a que Arment deje de criticar y se ponga a hablar Siracusa. 

En este episodio sin embargo hay dos personas que entienden Apple de la misma forma y argumentan y llegan a conclusiones interesantÃ­simas.

----
ğŸ¦ 8:00 AM Â· Mar 24, 2025 **Domingo Gallardo @domingogallardo**

Â¿Puede un LLM encontrar contradicciones en el texto escrito en su contexto? Â¿Depende esta capacidad del tamaÃ±o del contexto?

----
ğŸ¦ 4:58 PM Â· Mar 24, 2025 **Domingo Gallardo @domingogallardo**

TIL Los distintos conjuntos de nÃºmeros son â€œinvencionesâ€ para ecuaciones que no tienen soluciÃ³n con los conjuntos anteriores. 

Enteros: x + 1 = 0 no tiene soluciÃ³n en los naturales.

Racionales: 3x - 1 = 0 no tiene soluciÃ³n en los enteros.

Irracionales: x^2 - 2 =  0 no tiene soluciÃ³n en los racionales.

Imaginarios: x^2 + 1 = 0 no tiene soluciÃ³n en los irracionales.

----
ğŸ” RT 9:29 PM Â· Mar 24, 2025 **ARC Prize @arcprize**

Today we are announcing ARC-AGI-2, an unsaturated frontier AGI benchmark that challenges AI reasoning systems (same relative ease for humans).

Grand Prize: 85%, ~$0.42/task efficiency

Current Performance:
* Base LLMs: 0%
* Reasoning Systems: <4%

----
ğŸ” RT 9:45 PM Â· Mar 24, 2025 **FranÃ§ois Chollet @fchollet**

All ARC-AGI-2 tasks were seen by 4-9 people each (7 on average), and we only kept those that were solved by at least 2 people in under 2 attempts -- which demonstrates they can be solved, reproducibly, independently, by multiple people.

Our test sample wasn't made of math/physics PhDs -- we recruited Uber drivers, students, unemployed folks, pretty much anyone trying to make some money on the side. So we know these tasks are absolutely feasible by regular folks.

The average success rate per task in our sample was 60%.

ğŸ’¬ QUOTE Mar 24 **ARC Prize @arcprize**

Every ARC-AGI-2 task, however, is solved by at least two humans, quickly and easily. We know this because we tested 400 people live.

----
ğŸ” RT 10:21 PM Â· Mar 24, 2025 **ARC Prize @arcprize**

Excited to have Machine Learning Street Talk (@MLStreetTalk) as a launch partner for ARC-AGI-2, featuring a deep dive interview with co-founders @mikeknoop and @fchollet

Check out the full episode

[youtube.com](https://www.youtube.com/watch?v=M3b59lZYBW8)

----
ğŸ¦ 8:15 AM Â· Mar 25, 2025 **Domingo Gallardo @domingogallardo**

El debate sobre si es correcto o no realizar aprendizaje con las tareas pÃºblicas de ARC-AGI.

ğŸ–¼ï¸ **Imagen**: *Captura de una publicaciÃ³n en X (Twitter) de Oriol Vinyals comentando el lanzamiento de ARC-AGI-2. La imagen asociada muestra una galerÃ­a de recreativas con estÃ©tica retro y el texto ARC-AGI-2 en el centro. En su respuesta, Vinyals felicita el lanzamiento y sugiere evitar que los modelos entrenen con los propios datos del test, o bien dividir la clasificaciÃ³n en dos listas, para no desvirtuar el valor del benchmark.*

----
ğŸ” RT 10:35 AM Â· Mar 25, 2025 **Artificial Analysis @ArtificialAnlys**

DeepSeek takes the lead: DeepSeek V3-0324 is now the highest scoring non-reasoning model

This is the first time an open weights model is the leading non-reasoning model, a milestone for open source.

DeepSeek V3-0324 has jumped forward 7 points in Artificial Analysis Intelligence Index, now sitting ahead of all other non-reasoning models. It sits behind DeepSeekâ€™s own R1 in Intelligence Index, as well as other reasoning models from OpenAI, Anthropic and Alibaba, but this does not take away from the impressiveness of this accomplishment. Non-reasoning models answer immediately without taking time to â€˜thinkâ€™, making them useful in latency-sensitive use cases.

Three months ago, DeepSeek released V3 and we we wrote that there is a new leader in open source AI - noting that V3 came close to leading proprietary models from Anthropic and Google but did not surpass them.

Today, DeepSeek are not just releasing the best open source model - DeepSeek are now driving the frontier of non-reasoning open weights models, eclipsing all proprietary non-reasoning models, including Gemini 2.0 Pro, Claude 3.7 Sonnet and Llama 3.3 70B. This release is arguably even more impressive than R1 - and potentially indicates that R2 is going to be another significant leap forward.

Most other details are identical to the December 2024 version of DeepSeek V3, including:
â¤ Context window: 128k (limited to 64k on DeepSeekâ€™s first-party API)
â¤ Total parameters: 671B (requires >700GB of GPU memory to run in native FP8 precision - still not something you can run at home!)
â¤ Active parameters: 37B
â¤ Native FP8 precision
 â¤Text only - no multimodal inputs or outputs
â¤ MIT License

[artificialanalysis.ai](https://artificialanalysis.ai/)

----
ğŸ¦ 11:41 AM Â· Mar 23, 2025 **Domingo Gallardo @domingogallardo**

Â¿QuÃ© le preocupa mÃ¡s a nuestros polÃ­ticos, mejorar la realidad o mantenerse en el poder gracias a palabras, discursos y â€œrelatosâ€?

Tenemos que ser mucho mÃ¡s crÃ­ticos (ciudadanos, periodistas) y evaluar las iniciativas por sus resultados y no por sus intenciones. Hemos avanzado en muchos temas (feminismo, respeto a la diversidad), pero en otros como pobreza, vivienda o educaciÃ³n parece que nos hemos quedados estancados o que vamos para atrÃ¡s.

ğŸ’¬ QUOTE Mar 21 **Patricia PeirÃ³ @patriziapeiro**

â€œEstÃ¡ claro que hay fallos graves en el sistema de protecciÃ³n. Se trata de niÃ±os vulnerables, pues muchos tienen traumas previos, desarraigo familiar o no cuentan con redes de apoyo. Agresores y mafias lo aprovechan. Hay riesgo claro de explotaciÃ³n sexualâ€ 

[elpais.com](https://elpais.com/espana/2025-03-21/mas-de-1100-menores-tutelados-por-las-autonomias-han-denunciado-abusos-sexuales-desde-2019.html)

----
ğŸ” RT 1:05 PM Â· Mar 25, 2025 **Antonio Ortiz @antonello**

Google acaba de liberar el cÃ³digo de Alexnet

Para todos los interesados en la historia de la inteligencia artificial, Alexnet en 2012 supuso un enorme punto de inflexiÃ³n: 

arrasÃ³ en el concurso Imagenet y mostrÃ³ el nuevo camino de la IA: avance con mucho contenido y computaciÃ³n

ğŸ–¼ï¸ **Imagen**: *Captura de una entrada del blog del Computer History Museum (CHM) anunciando la publicaciÃ³n del cÃ³digo fuente de AlexNet, fechada el 20 de marzo de 2025 y firmada por Hansen Hsu. A la derecha, se muestra una fotografÃ­a del equipo original de AlexNet: Alex Krizhevsky, Ilya Sutskever y Geoffrey Hinton, de izquierda a derecha. EstÃ¡n de pie frente a una pizarra con diagramas de redes neuronales dibujados. Hinton, en primer plano, sonrÃ­e con los brazos cruzados. El fondo de la web es beige, con diseÃ±o sobrio y tipografÃ­a en negro.*

----
ğŸ¦ 1:58 PM Â· Mar 25, 2025 **Domingo Gallardo @domingogallardo**

Seguimos actualizando el blog:

[domingogallardo.com](https://domingogallardo.com/posts/exploramos-el-razonamiento-de-deepseek-r1/)

----
ğŸ” RT 6:45 PM Â· Mar 25, 2025 **OpenAI @OpenAI**

4o image generation in ChatGPT and Sora
From openai.com

[openai.com](https://openai.com/live/)

----
ğŸ” RT 9:53 PM Â· Mar 25, 2025 **Paul Gauthier @paulgauthier**

Gemini 2.5 Pro sets SOTA on the aider polyglot leaderboard with a score of 73%.

This is well ahead of thinking/reasoning models. A huge jump from prior Gemini models. The first Gemini model to effectively use efficient diff-like editing formats.

[aider.chat](https://aider.chat/docs/leaderboards/)

ğŸ–¼ï¸ **Imagen**: *GrÃ¡fico de barras con los resultados del benchmark Aider polyglot, que evalÃºa la capacidad de modelos de lenguaje para completar correctamente tareas de ediciÃ³n de cÃ³digo en mÃºltiples lenguajes. El eje vertical indica el porcentaje de tareas completadas con Ã©xito y el eje derecho, el coste total en dÃ³lares (representado con puntos morados).*

*El modelo Gemini 2.5 Pro exp-03-25 destaca como el mÃ¡s preciso (73â€¯%) y estÃ¡ marcado con una barra roja. Le siguen modelos como Claude 3.7 Sonnet, o1 17 (high), o3-mini y DeepSeek, todos con barras azules que representan el uso del formato diff-like. Gemini 2.0 queda en Ãºltimo lugar, con menor precisiÃ³n pero menor coste.*

----
4:10 PM Â· Mar 25, 2025 **Dwarkesh Patel @dwarkesh_sp**

I'm so pleased to present a new book with @stripepress: "The Scaling Era: An Oral History of AI, 2019-2025."

Over the last few years, I interviewed the key people thinking about AI: scientists, CEOs, economists, philosophers. This book curates and organizes the highlights across all these conversations.

You get to see thinkers across many, many fields address the same gnarly questions: â€œWhat is the true nature of intelligence? What will change from the millions of machine intelligences running around? What exactly will it take to get there?â€

Settled answers are unavailable; weâ€™re all running unsupervised. But between these discussions lie, I hope, some insights on the most interesting and important questions of our era.

ğŸ–¼ï¸ **Imagen**: *FotografÃ­a de un libro abierto con diseÃ±o editorial cuidado. El tÃ­tulo del capÃ­tulo no se muestra, pero el contenido trata sobre el enorme crecimiento del cÃ³mputo necesario para entrenar modelos de IA, citando casos como GPT-3 y LLaMA 2. En la pÃ¡gina derecha hay un grÃ¡fico con puntos de colores que compara el coste de entrenamiento frente a la fecha de publicaciÃ³n. Aparecen tambiÃ©n citas de expertos como Dwarvesh Patel y Leopold Aschenbrenner. El libro es The Scaling Era: An Oral History of AI, 2019â€“2025, publicado por Stripe Press.*

Link below. Enjoy!

[press.stripe.com](https://press.stripe.com/scaling)

----
ğŸ” RT 5:47 AM Â· Mar 26, 2025 **Ethan Mollick @emollick**

Gemini 2.5 Pro is a very good model, seems like a real step forward, in both metrics and practical use.

I think because it is labelled 2.5 and was sort of quietly rolled out, people may miss how big a jump it is, but discussions are making me think others are feeling similarly.

----
ğŸ¦ 8:05 AM Â· Mar 26, 2025 **Domingo Gallardo @domingogallardo**

Jugando con las imÃ¡genes de ChatGPT ğŸ˜„

ğŸ–¼ï¸ **Imagen**: *IlustraciÃ³n de estilo retro-futurista. Un personaje humano con traje espacial saluda con entusiasmo a dos figuras alienÃ­genas: un caracol-robot y un simpÃ¡tico extraterrestre verde con ojos saltones. El texto en un bocadillo dice: â€œÂ¡CUÃNTO TIEMPO SIN VERTE! Â¿QUÃ‰ TE CUENTAS, AMIGO?â€. El fondo muestra un paisaje marciano con vegetaciÃ³n estilizada, dos planetas y una torre al estilo de comunicaciones.*

----
ğŸ” RT 8:34 AM Â· Mar 26, 2025 **Antonio Ortiz @antonello**

Ha costado un par de intentos, pero conseguido

el pintar una copa de vino llena hasta el borde es una prueba muy difÃ­cil para un modelo generador de imÃ¡genes por una razÃ³n muy sencilla:

en los datos de entranamiento tiene miles de copas llenas 2/3 en el dataset

ğŸ–¼ï¸ **Imagen**: *Captura de pantalla de una conversaciÃ³n con una IA generadora de imÃ¡genes. El prompt indica: â€œcrea una copa de vino absolutamente llena hasta el bordeâ€. Debajo aparece una ilustraciÃ³n digital de una copa de vino tinto, completamente llena hasta el borde superior. El fondo es de tono beige, con textura que simula papel. La copa tiene un pie clÃ¡sico y la superficie del vino se muestra nivelada, al borde del derrame, en clara contradicciÃ³n con la representaciÃ³n habitual en datasets de entrenamiento.*

----
ğŸ” RT 9:47 AM Â· Mar 26, 2025 **Domingo Gallardo @domingogallardo**

Wall? what wall?

ğŸ’¬ QUOTE Mar 25 **Demis Hassabis @demishassabis**

Gemini 2.5 Pro is an awesome state-of-the-art model, no.1 on LMArena by a whopping +39 ELO points, with significant improvements across the board in multimodal reasoning, coding & STEM. You can try it out now in AI Studio [ai.dev](http://ai.dev) & @GeminiApp with Gemini Advanced

----
ğŸ¦ 8:31 PM Â· Mar 26, 2025 **Domingo Gallardo @domingogallardo**

#NewProfilePic

ğŸ–¼ï¸ **Imagen**: *IlustraciÃ³n de estilo anime que representa a un hombre de mediana edad con gafas, canas y camisa azul, sonriendo frente a una estanterÃ­a llena de libros. A su lado se ve una taza blanca con el logo de GitHub y una maqueta del mÃ³dulo lunar del Apolo. El estilo transmite calidez y familiaridad, tÃ­pico de los retratos generados con IA para perfiles tecnolÃ³gicos.*

----
ğŸ¦ 8:02 AM Â· Mar 27, 2025 **Domingo Gallardo @domingogallardo**

Usando 4o para recordar cosas con las que siempre me lÃ­o

ğŸ–¼ï¸ **Imagen**: *IlustraciÃ³n en blanco y negro de estilo manga. Una mujer joven con traje de chaqueta seÃ±ala una pantalla de presentaciÃ³n con una varita. El texto proyectado dice:*
*â€œSi el valor EUR/USD sube: â€“ el dÃ³lar se debilita â€“ tus acciones pierden valorâ€.*
*La imagen transmite una explicaciÃ³n didÃ¡ctica, idealizada con estÃ©tica anime, usada aquÃ­ como recurso visual para memorizar un concepto de economÃ­a bÃ¡sica sobre el tipo de cambio.*

----
ğŸ” RT 7:53 AM Â· Mar 27, 2025 **PJ Ace @PJaccetturo**

What if Studio Ghibli directed Lord of the Rings?

I spent $250 in Kling credits and 9 hours re-editing the Fellowship trailer to bring that vision to lifeâ€”and Iâ€™ll show you exactly how I did it ğŸ‘‡ğŸ¼

ğŸ–¼ï¸ **Imagen**: *Fotograma de un vÃ­deo editado que imagina cÃ³mo serÃ­a The Fellowship of the Ring si hubiera sido dirigida por Studio Ghibli. El estilo visual imita la animaciÃ³n tradicional del estudio japonÃ©s, con montaÃ±as frondosas envueltas en niebla pintadas a mano. Sobre el paisaje aparece el texto: â€œSTUDIO GHIBLI PRESENTS: THE FELLOWSHIP OF THE RINGâ€, en una tipografÃ­a clÃ¡sica de fantasÃ­a. La barra de reproducciÃ³n indica que el vÃ­deo dura 1:52 y estÃ¡ en el segundo 0:02.*

----
ğŸ¦ 6:46 PM Â· Mar 27, 2025 **Domingo Gallardo @domingogallardo**

Escuchando el podcast sobre el libro de Ezra Klein. Hay que transformar el discurso progresista (ellos lo llaman â€œliberalâ€, pero aquÃ­ esa palabra estÃ¡ maldita) desde uno del reparto de lo escaso a otro de la construcciÃ³n y de la abundancia. 

AquÃ­ tenemos a gente como @antonello, @kikollan, @JorgeGalindo con un discurso similar. Bravo, a ver si estas ideas empiezan a llegar a los polÃ­ticos.

ğŸ’¬ QUOTE Mar 26 **Ezra Klein @ezraklein**

So much of "Abundance" is about failures of government in California specifically. So I was pretty damn interested to hear what @GavinNewsom thought of it, and how he'd answer some of those critiques...

Then he invited me on his podcast.

[youtube.com](https://www.youtube.com/watch?v=Bt_LQNS7hmU)

----
ğŸ¦ 9:36 AM Â· Mar 28, 2025 **Domingo Gallardo @domingogallardo**

Ahora que lo de las imÃ¡genes de Ghibli estÃ¡ apagÃ¡ndose (y lo que nos falta por ver en forma de demandas), yo me quedo con lo que que nos ha dado de disfrute. Me ha recordado la Ã©poca de las fotocopias de Goku, en la que Ã­bamos a Ateneo a comprar fanzines piratas de Bola de Drac.

ğŸ–¼ï¸ **Imagen**: *IlustraciÃ³n en blanco y negro de Son Goku niÃ±o, personaje principal del manga Dragon Ball creado por Akira Toriyama. Aparece con su caracterÃ­stico peinado en puntas, una gran sonrisa y la cola de mono visible, rasgo distintivo de su raza saiyajin. Lleva puesto un gi de artes marciales con cinturÃ³n y zapatos planos, y adopta una pose confiada con las manos en la cintura y las piernas ligeramente separadas. El estilo de trazo y la calidad de impresiÃ³n sugieren que se trata de una imagen antigua, posiblemente un boceto o pÃ¡gina escaneada del manga original.*

----
ğŸ” RT 11:11 AM Â· Mar 28, 2025 **Artificial Analysis @ArtificialAnlys**

Todayâ€™s GPT-4o update is actually big - it leapfrogs Claude 3.7 Sonnet (non-reasoning) and Gemini 2.0 Flash in our Intelligence Index and is now the leading non-reasoning model for coding

This makes GPT-4o the second highest scoring non-reasoning model (excludes o3-mini, Gemini 2.5 Pro, etc), coming in just behind DeepSeekâ€™s V3 0324 release earlier this week.

Key benchmarking results:
â¤ Significant jump in the Artificial Analysis Intelligence Index from 41 to 50, putting GPT-4o (March 2025) ahead of Claude 3.7 Sonnet
â¤ Now the the leading non-reasoning model for coding:  ğŸ¥‡#1 in the Artificial Analysis Coding Index and in LiveCodeBench, surpassing DeepSeek V3 (March 2025) and Claude 3.7 Sonnet

@OpenAI
 has committed an all-new AI model naming sin of simply refusing to name the model at all, so we will be referring to it as GPT-4o (March 2025).

This update has also been released in a fairly confusing way - the March 2025 version of GPT-4o is currently available:
â¤ In ChatGPT, when users select GPT-4o in the model selector
â¤ Via API on the chatgpt-4o-latest endpoint - a non-dated endpoint that OpenAI described at launch as intended for research use only, with developers encouraged to use the dated snapshot versions of GPT-4o for most API use cases

As of today, this means that the chatgpt-4o-latest endpoint is serving a significantly better model than the proper API versions GPT-4o (ie. the August 2024 and November 2024 snapshots).

We recommend some caution for developers considering moving workloads to the chatgpt-4o-latest endpoint given OpenAIâ€™s previous guidance, and note that OpenAI will likely release a dated API snapshot soon. We also note that OpenAI prices the chatgpt-4o-latest endpoint at $5/$15 per million input/output tokens, whereas the API snapshots are priced at $2.5/$10.

See below for further analysis ğŸ‘‡

---
ğŸ” RT 1:05 PM Â· Mar 28, 2025 **Ethan Mollick @emollick**

I do think the AI art trends (and resultant controversies) obscure the fact that multimodal image output allows AI to start to address entirely new problem spaces that used to be outside of what AI can do, and now appear to be pretty trivial, either now or in the near future.

ImÃ¡genes: *Estas dos imÃ¡genes muestran ejemplos del uso de la generaciÃ³n de imÃ¡genes multimodal para resolver tareas prÃ¡cticas:*
	*1.	Primera imagen: Un entorno generado digitalmente donde se ha aÃ±adido una lÃ¡mpara a la derecha de un sofÃ¡, a partir de la instrucciÃ³n dada. Ilustra cÃ³mo los modelos pueden editar imÃ¡genes con instrucciones precisas para visualizar cambios en decoraciÃ³n de interiores o diseÃ±o.*
	*2.	Segunda imagen: Un diseÃ±o conceptual de una app llamada GuacCopter, donde un dron entrega guacamole a demanda. Muestra cÃ³mo la IA puede generar maquetas realistas de interfaces mÃ³viles a partir de ideas textuales, facilitando el prototipado rÃ¡pido de productos.
	
----
6:09 PM Â· Mar 28, 2025 RT **Kevin Roose @kevinroose**

It's Hard Fork Friday! This week on the show:

â€” What Signalgate says about the government's tech deficit
â€” We locked @dwarkesh_sp in a studio to stop him from overtaking us in podcasting (also he has a new book!)
â€” And our listeners tell us whether AI is making them dumb

----
ğŸ¦ 8:40 AM Â· Mar 29, 2025 **Domingo Gallardo @domingogallardo**

Si antes ya estaba claro , ahora ya es mÃ¡s que evidente: todos escribimos para Grok. No me parece mal. Empezamos escribiendo para â€œla webâ€, que despuÃ©s se convirtiÃ³ Google y ahora va a ser sustituido por los LLMs. Todo evoluciona.

ğŸ’¬ QUOTE Mar 29 monos **estocÃ¡sticos @monospodcast**

ahora estamos todos en xAI

----
ğŸ” RT 6:48 AM Â· Mar 29, 2025 **Paul Gauthier @paulgauthier**

The latest ChatGPT-4o scored 45% on the aider polyglot coding benchmark. This is a big step up from the previous version.

[aider.chat](https://aider.chat/docs/leaderboards/)

ğŸ–¼ï¸ **Imagen**: *GrÃ¡fico que compara el rendimiento y coste de distintos modelos en el benchmark Aider polyglot, centrado en tareas de ediciÃ³n de cÃ³digo. Gemini 2.5 Pro lidera con un 73% de aciertos, seguido de DeepSeek V3 con buen equilibrio entre rendimiento y coste. Las versiones mÃ¡s recientes de ChatGPT-4o mejoran respecto a anteriores, aunque siguen por detrÃ¡s en precisiÃ³n.*

----
ğŸ” RT 12:20 PM Â· Mar 29, 2025 **Kiko Llaneras @kikollan**

Entiendo 100% la polÃ©mica con los derechos de Studio Ghibli. 

Al mismo tiempo creo que es un tributo *gigante* que millones de personas quieran imitarte. Â¡Imaginad llenar internet de derivados artificiales que evocan algo que tÃº creaste!

No lo digo como justificaciÃ³n. 

Lo digo porque es parte del episodio. La inundaciÃ³n de imÃ¡genes artificiales inspiradas en Ghibli tambiÃ©n es una celebraciÃ³n de sus obras, y sobre todo, una expresiÃ³n de asombro compartido ante una hito tecnolÃ³gico quÃ© tendrÃ¡ consecuencias sociales, econÃ³micas, creativas y filosÃ³ficas.

Por supuesto, no sÃ© quÃ© pensarÃ¡n los artistas de Studio. Yo creo que alcanzar ese reconocimiento es tambiÃ©n un privilegio. Uno que casi nadie tiene. Muy pocos creadores logran ese nivel de atenciÃ³n y cariÃ±o. Y la mayorÃ­a de las personas nunca pueden crear algo que otros admirarÃ¡n. Crear es raro, crear con Ã©xito es rarÃ­simo, y crear con *ese Ã©xito* es simplemente insÃ³lito.

----
ğŸ” RT 7:19 PM Â· Mar 29, 2025 **Javier Atapuerca @JaviAtapu**

Esta historia es, bÃ¡sicamente, un pequeÃ±o homenaje a una de mis series favoritas, Â«Star Trek: La Nueva GeneraciÃ³nÂ». Y la forma de hacer ese homenaje es a travÃ©s delâ€¦ Â¿Excel?

Porque, Â¿por quÃ© no recrear su icÃ³nica interfaz en una anodina hoja de cÃ¡lculo?

----
ğŸ” RT 10:40 AM Â· Mar 30, 2025 **Domingo Gallardo @domingogallardo**

QuÃ© buena Manuela Carmena. Me voy corriendo a comprar sus memorias.

Sobre la burocracia: â€œMe he encontrado que en algo tan precioso como lo pÃºblico nos atamos las manos, nos ponemos un solo guante en las dos, las dejamos apresadas y no podemos hacer lo que deberÃ­amos, que es tan necesario y fascinante. Si consigues quitar el guante es maravilloso, pero la AdministraciÃ³n estÃ¡ llena de gente con las manos metidas en uno solo.â€

Sobre el la falta de diÃ¡logo en la polÃ­tica: â€œla decepciÃ³n que produce la democracia por no cuidarla ha hecho que muchos jÃ³venes miren hacia gobiernos autoritarios. Hemos convertido la democracia en procesos de enfrentamiento dialÃ©ctico absolutamente ajenos a la gestiÃ³n pÃºblica.â€

Sobre el sectarismo que se encontrÃ³ en Podemos: â€œAntes creÃ­a que los activistas eran los mÃ¡s indicados para la polÃ­tica, pero me di cuenta de que no. Me llevÃ© una desilusiÃ³n. TenÃ­an tan claros los objetivos finales que estos nunca debÃ­an desdibujarse en la gestiÃ³n. Vi una gran dificultad para pactar, para ceder, para ver a los demÃ¡s. Y eso me produjo inquietud. No pensaba que me iba a pasar, pero el activismo sectariza mucho.â€

----
ğŸ¦ 12:09 PM Â· Mar 31, 2025 **Domingo Gallardo @domingogallardo**

"CÃ³mo ejecutar DeepSeek-R1" un post un poco desfasado (ahora que ya estÃ¡ rumoreando R2), pero con  consejos sobre cÃ³mo usar el terminal, instalar modelos locales y ejecutar scripts de Python que lancen el modelo en un proveedor.

El enlace al post:

[domingogallardo.com](https://domingogallardo.com/posts/como-ejecutar-deepseek-r1/)

----
ğŸ” RT 2:22 PM Â· Mar 31, **2025 Francisco Gallego @FranGallegoBR**

MaÃ±ana,1 abril 2025 #UAGamesDevCon2025

- 5 #Charlas profesionales de #Videojuegos con @antojbf, @Azicuetano, @yarosisisi, @Daninimas1, @Rox_GD
- ExposiciÃ³n interactiva de 9 proyectos en desarrollo

Â¡No te lo pierdas!

[eps.ua.es](https://eps.ua.es/es/ingenieria-multimedia/videojuegos/webs-uagames/uagames-devcon-2025.html)

----
ğŸ” RT 9:39 PM Â· Mar 31, 2025 **Sam Altman @sama**

TL;DR: we are excited to release a powerful new open-weight language model with reasoning in the coming months, and we want to talk to devs about how to make it maximally useful: [openai.com](https://openai.com/open-model-feedback)

we are excited to make this a very, very good model!

__

we are planning to release our first open-weigh language model since GPT-2.

weâ€™ve been thinking about this for a long time but other priorities took precedence. now it feels important to do.

before release, we will evaluate this model according out our preparedness framework, like we would for any other model. and we will do extra work given that we know this model will be modified post-release.

we still have some decisions to make, so we are hosting developer events to gather feedback and later play with early prototypes. weâ€™ll start in SF in a couple of weeks followed by sessions in europe and APAC. if you are interested in joining, please sign up at the link above.

weâ€™re excited to see what developers build and how large companies and governments use it where they prefer to run a model themselves.

[openai.com](https://openai.com/open-model-feedback)

----
ğŸ” RT 5:06 PM Â· Mar 19, 2025 **Le Random @lerandomart**

"THE PEOPLE ARE IN THE COMPUTERâ€”PART I" by Peter Bauman 

The story of Alec Radford @AlecRad ChatGPT's inventor + his foundational contributions to generative AI

ğŸ“–: [lerandom.art](https://www.lerandom.art/editorial/the-people-are-in-the-computer--part-i)
