---
title: "Del 16 al 30 de junio (#12 de 2024)"
date: 2024-07-05
draft: false
tags:
  - "newsletter"
---
<p>Un viernes m√°s comentando lo sucedido en la quincena pasada, del 16 al 30 de junio. Una quincena con muchas novedades y reflexiones sobre los LLMs. Muchas novedades, y tambi√©n muchas incertidumbres.</p>

<p>¬°Gracias por leerme!</p>

<h2>üóû Noticias</h2>

<p>
</p>

<p>1Ô∏è‚É£ Ahora que ha llegado el verano, es un buen momento de repasar la <strong>evoluci√≥n de la temperatura global del planeta</strong> de la que <a href="/posts/del-1-al-15-de-abril-7-de-2024/">hablamos en abril</a>. Todos los datos est√°n sacados, como en la anterior entrada, de la web <a href="https://climatereanalyzer.org/">https://climatereanalyzer.org/</a> del Climate Change Institute de la universidad de Maine. ¬øTendremos un verano tan caluroso como el del a√±o pasado?</p>

<p>La&nbsp;<a href="https://climatereanalyzer.org/clim/t2_daily/?dm_id=nh">temperatura del aire en el hemisferio norte</a>&nbsp;nos da algo de esperanza. </p>

<p>
<img src="Captura de pantalla 2024-07-04 a las 12.05.10.png" alt="">
</p>

<p>La l√≠nea negra gruesa es la evoluci√≥n de la temperatura este a√±o. ¬øEmpieza a bajar?</p>

<p>La l√≠nea naranja muestra la temperatura del a√±o pasado. A comienzos de julio fue de 21,7 ¬∫C (+1,1 ¬∫C sobre la media) y termin√≥ el mes siendo 22,7 ¬∫C (+1,4 ¬∫C). La l√≠nea negra gruesa es la temperatura de este a√±o. Parece que empieza a bajar, pero todav√≠a es pronto para sacar conclusiones. Mejor verlo en un par de semanas, cuando estemos a mitad de mes.</p>

<p>La gr√°fica que m√°s nos refresca es la&nbsp;<a href="https://climatereanalyzer.org/clim/sst_daily/">temperatura del mar en el hemisferio norte</a>, que por fin est√° m√°s baja que la del a√±o pasado.</p>

<p>
<img src="Captura de pantalla 2024-07-04 a las 12.13.43.png" alt="">
</p>

<p>Parece que empieza a refrescar.</p>

<p>¬øPuede ser que ya haya&nbsp;<a href="https://www.climate.gov/enso">terminado El Ni√±o</a>? ¬øQue ya est√©n empezando a desaparecer los efectos del vapor de agua de la&nbsp;<a href="/posts/del-1-al-15-de-abril-7-de-2024/">erupci√≥n del Hunga Tonga</a>? Crucemos los dedos para que <strong>la l√≠nea negra siga avanzando en horizantal</strong>.&nbsp;</p>

<p>2Ô∏è‚É£ El 17 de junio, la empresa&nbsp;<a href="https://runwayml.com/">Runway</a>&nbsp;present√≥ su <strong>nuevo modelo de generaci√≥n de secuencias de v√≠deo</strong>&nbsp;<a href="https://runwayml.com/blog/introducing-gen-3-alpha/">Gen-3 Alpha</a>. Los v√≠deos son secuencias de unos pocos segundos, con una gran calidad y consistencia, similares a los que&nbsp;<a href="/posts/del-16-al-29-de-febrero-4-de-2024/">ya vimos</a>&nbsp;del modelo de OpenAI, Sora.</p>

<div class="native-video-embed" data-component-name="VideoPlaceholder" data-attrs="{&quot;mediaUploadId&quot;:&quot;2c8b03a1-d573-4582-bcb4-ac5cd5e93ca2&quot;,&quot;duration&quot;:null}">
</div>
<p>A diferencia de OpenAI, Runway ya&nbsp;<a href="https://app.runwayml.com/signup">ha abierto</a>&nbsp;el acceso a la herramienta. Para generar v√≠deos con este √∫ltimo modelo debes suscribirte al plan de pago, de $12 al mes. Yo ya tengo bastante con pagar a OpenAI y este mes ya me he gastado el presupuesto para caprichos en Sonnet 3.5. Pero en X se pueden ver un mont√≥n de ejemplos de gente que lo est√° probando. Por ejemplo, los espaghettis danzarines de&nbsp;<a href="https://x.com/javilopen/status/1808140481232359736">Javi L√≥pez</a>.</p>

<div class="native-video-embed" data-component-name="VideoPlaceholder" data-attrs="{&quot;mediaUploadId&quot;:&quot;64be3565-2b5d-42c4-989a-f94dd8b98c08&quot;,&quot;duration&quot;:null}">
</div>
<p>Hay alguien que incluso&nbsp;<a href="https://www.reddit.com/r/OpenAI/comments/1dti3j3/sora_vs_runway_side_by_side_comparison/">ha publicado en Reddit</a> una comparativa entre los v√≠deos generados por Sora y los de Gen-3 Alpha, usando los prompts del v√≠deo de promoci√≥n de OpenAI.</p>

<p>
<img src="sora-gen3.png" alt="">
</p>

<p>Sigo diciendo lo que ya coment√© en febrero. Me parecen avances impresionantes, pero tenemos <strong>muy poco control sobre el resultado</strong> y no creo que sea posible escalar su uso a producir un corto o una pel√≠cula. Ni tampoco me interesa. Cuando voy al cine quiero ver algo <strong>creado por personas e interpretado por personas</strong>. Y si es una pel√≠cula de animaci√≥n, quiero ver una obra consistente, coherente, que me transmita sensaciones mediante secuencias dise√±adas y dirigidas por autores humanos, que vuelcan toda su experiencia en una obra. No me interesa lo que genera una IA de forma aleatoria en el marco de un <em>prompt</em> de texto.</p>

<p>3Ô∏è‚É£ <strong>Fran√ßois Chollet</strong> ha aparecido en varios podcasts, como resultado de la repercusi√≥n de su <a href="https://arcprize.org">competici√≥n ARC</a> de la que hablamos <a href="/posts/del-1-al-15-de-junio-11-de-2024/">la quincena pasada</a>. Despu√©s de escuchar completas las entrevistas que le hacen <strong>Dwarkesh Patel</strong> y <strong>Sean Carroll</strong>, me he convertido en un fan total. Chollet lleva trabajando con redes neuronales y deep learning desde mediados de la d√©cada pasada y su librer√≠a <a href="https://keras.io">Keras</a> para redes neuronales es ampliamente usada en la comunidad. Se trata de una persona muy t√©cnica, que sabe de lo que habla.</p>

<p>El podcast con Dwarkesh Patel ya lo referenciamos la quincena pasada. Pongo a continuaci√≥n los enlaces a los podcasts mencionados, sus transcripciones y algunos comentarios y citas de sus transcripciones.</p>

<p>El podcast de <strong>Dwarkesh Patel</strong>:</p>

<div class="apple-podcast-container" data-component-name="ApplePodcastToDom">
<iframe class="apple-podcast " data-attrs="{&quot;url&quot;:&quot;https://embed.podcasts.apple.com/es/podcast/dwarkesh-podcast/id1516093381?i=1000658672649&quot;,&quot;isEpisode&quot;:true,&quot;imageUrl&quot;:&quot;podcast-episode_1000658672649.jpg&quot;,&quot;title&quot;-&quot;Francois Chollet, Mike Knoop - LLMs won‚Äôt lead to AGI - $1,000,000 Prize to find true solution&quot;,&quot;podcastTitle&quot;:&quot;Dwarkesh Podcast&quot;,&quot;podcastByline&quot;:&quot;&quot;,&quot;duration&quot;:5633000,&quot;numEpisodes&quot;:&quot;&quot;,&quot;targetUrl&quot;:&quot;https://podcasts.apple.com/es/podcast/francois-chollet-mike-knoop-llms-wont-lead-to-agi-%241/id1516093381?i=1000658672649&amp;uo=4&quot;,&quot;releaseDate&quot;:&quot;2024-06-11T17:03:59Z&quot;}" src="https://embed.podcasts.apple.com/es/podcast/dwarkesh-podcast/id1516093381?i=1000658672649" frameborder="0" allow="autoplay *; encrypted-media *;" allowfullscreen="true">
</iframe>
</div>
<p>Su transcripci√≥n se puede encontrar <a href="https://www.dwarkeshpatel.com/p/francois-chollet">en substack</a>.</p>

<p>Me ha parecido interesant√≠sima la idea de Chollet de interpretar los LLMs como una ‚Äú<strong>gran memoria interpolativa</strong>‚Äù, una enorme colecci√≥n de programas que implementan patrones aprendidos durante el aprendizaje. Cuando a un LLM se le hace una consulta, realiza <strong>una interpolaci√≥n</strong> entre los patrones que se ajustan mejor a la respuesta.</p>

<blockquote>
<p>‚ÄúLa forma en que funcionan los LLM es que b√°sicamente son una gran memoria interpolativa. La forma en que aumentas sus capacidades es tratando de meter la mayor cantidad posible de conocimiento y patrones en ellos.‚Äù</p>

</blockquote>

<p>Seg√∫n Chollet, esta forma de funcionar de un LLM solo le permite una inteligencia muy limitada, no es capaz de combinar los programas que ha aprendido para, en un proceso de b√∫squeda, inventar un nuevo "programa" que resuelva una situaci√≥n novedosa, no incluida en su base de datos de aprendizaje. Para Chollet, la posibilidad de realizar <strong>b√∫squedas combinatoriales</strong> es un elemento fundamental de la inteligencia. Por ejemplo, cuando jugamos al ajedrez o al <strong>Rummikub</strong>, debemos buscar posibles combinaciones y escoger la mejor. Esto no lo puede hacer un LLM:</p>

<blockquote>
<p>Para obtener novedades, necesitas b√∫squeda. Los LLMs no pueden realizar b√∫squedas, solo pueden realizar interpolaci√≥n.</p>

</blockquote>

<p>Para Chollet los LLMs son herramientas poderosas para la <strong>memorizaci√≥n</strong> y la aplicaci√≥n de conocimientos y patrones conocidos, pero carecen de la capacidad de adaptarse y crear soluciones novedosas, lo cual es crucial para alcanzar una verdadera inteligencia general.</p>

<p>Chollet tambi√©n es <strong>cr√≠tico con que el escalado de los modelos lleve a modelos que generalizan mejor</strong>. Para √©l, lo que pasa es que aumentan la cantidad de habilidades y de datos, pero eso no significan que sean m√°s inteligentes:</p>

<blockquote>
<p>‚ÄúSi ampl√≠as tu base de datos y sigues a√±adiendo m√°s conocimiento y plantillas de programas a ella, entonces, claro, se vuelve m√°s y m√°s h√°bil. Puedes aplicarlo a m√°s y m√°s tareas. Pero la inteligencia general no es una habilidad espec√≠fica de tarea ampliada a muchas habilidades, porque existe un espacio infinito de posibles habilidades.‚Äù</p>

</blockquote>

<p>A pesar de todo esto, Chollet defiende que los LLMs tienen su utilidad y su aplicaci√≥n. Dice que los LLMs, como otros sistemas de deep learning, pueden reconocer y aplicar patrones de manera eficiente. Por ello son excelentes para la <strong>inteligencia de "tipo 1"</strong>, inteligencia basada en la intuici√≥n, el reconocimiento de patrones y la memorizaci√≥n. Este tipo de inteligencia es r√°pido y autom√°tico, utilizado para tareas que no requieren un razonamiento profundo o deliberado. Sin embargo, existe otra forma de inteligencia humana, lenta y deliberada, basada en el razonamiento, la planificaci√≥n y la s√≠ntesis de nuevos programas o soluciones.</p>

<p>Fran√ßois Chollet sugiere que, para avanzar hacia una verdadera inteligencia general, es necesario desarrollar sistemas h√≠bridos que combinen el aprendizaje profundo con la b√∫squeda y exploraci√≥n para generar nuevos programas, combinando los ya aprendidos. De esta forma se podr√≠a aprovechar las fortalezas de ambos tipos de inteligencia.</p>

<p>La entrevista con <strong>Sean Carroll</strong> en su Mindscape podcast est√° disponible en el siguiente enlace:</p>

<div class="apple-podcast-container" data-component-name="ApplePodcastToDom">
<iframe class="apple-podcast " data-attrs="{&quot;url&quot;:&quot;https://embed.podcasts.apple.com/es/podcast/sean-carrolls-mindscape-science-society-philosophy/id1406534739?i=1000660048303&quot;,&quot;isEpisode&quot;:true,&quot;imageUrl&quot;:&quot;podcast-episode_1000660048303.jpg&quot;,&quot;title&quot;-&quot;Fran%C3%A7ois Chollet on Deep Learning and the Meaning of Intelligence&quot;,&quot;podcastTitle&quot;:&quot;Sean Carroll's Mindscape: Science, Society, Philosophy, Culture, Arts, and Ideas&quot;,&quot;podcastByline&quot;:&quot;&quot;,&quot;duration&quot;:6109000,&quot;numEpisodes&quot;:&quot;&quot;,&quot;targetUrl&quot;:&quot;https://podcasts.apple.com/es/podcast/fran%C3%A7ois-chollet-on-deep-learning-and-the/id1406534739?i=1000660048303&amp;uo=4&quot;,&quot;releaseDate&quot;:&quot;2024-06-24T11:45:38Z&quot;}" src="https://embed.podcasts.apple.com/es/podcast/sean-carrolls-mindscape-science-society-philosophy/id1406534739?i=1000660048303" frameborder="0" allow="autoplay *; encrypted-media *;" allowfullscreen="true">
</iframe>
</div>
<p>Y la transcripci√≥n est√° <a href="https://www.preposterousuniverse.com/podcast/2024/06/24/280-francois-chollet-on-deep-learning-and-the-meaning-of-intelligence/">el blog de Sean Carroll</a>.</p>

<p>La entrevista es muy interesante, <strong>m√°s did√°ctica</strong> que la primera. Carroll pide m√°s de una vez aclaraciones sobre aspectos que la audiencia puede que no entienda (algoritmos gen√©ticos, transformers, espacios vectoriales, etc.) y Chollet se esfuerza en explicarlos.</p>

<p>Chollet se moja bastante en la entrevista y argumenta que hemos llegado a una especie de <strong>meseta</strong> en la mejora de los LLMs, debida a la falta de datos de entrenamiento:</p>

<blockquote>
<p>‚ÄúLa curva [que representa la mejora de los LLMs] necesita ajustarse a algo. La curva es literalmente solo una representaci√≥n de un conjunto de datos de entrenamiento. Si te has quedado sin datos, entonces, ¬øc√≥mo mejoras el modelo? Bueno, una forma es que puedes intentar curar mejor tus datos de entrenamiento. As√≠ que no aumentas la escala de los datos de entrenamiento, pero puedes aumentar la calidad. Esa es realmente una forma muy prometedora de mejorar los modelos de lenguaje grande. Es en realidad la forma en que los modelos de lenguaje grande siguen mejorando hoy en d√≠a. Ya nos hemos quedado sin datos. As√≠ que la siguiente etapa es que curamos mejor los datos. No estamos entrenando los modelos de lenguaje grande con m√°s datos, en realidad los estamos curando. T√©cnicamente, todav√≠a estamos recolectando nuevos datos de evaluadores humanos. As√≠ que hay un poco de aumento, pero en balance, en realidad est√° disminuyendo. Pero no vas a encontrar m√°gicamente mil veces m√°s datos nuevos y no redundantes para entrenar estos modelos. Simplemente no existen. Ni siquiera vas a encontrar el doble. Y esa es la causa de la meseta que hemos estado viendo.‚Äù</p>

</blockquote>

<p>Y esta meseta va a causar una decepcion:</p>

<blockquote>
<p>‚ÄúEsa es la causa de la meseta que hemos estado viendo. Y algo como GPT-5 probablemente ser√° lanzado a finales de este a√±o. Va a ser una gran decepci√≥n porque no va a ser significativamente mejor que GPT-4.‚Äù</p>

</blockquote>

<p>Por √∫ltimo, sobre los problemas que nos puede traer la IA, y sobre el riesgo existencial de la IA, Chollet tiene una postura muy similar a la que ya hemos comentado por aqu√≠ en otras ocasiones. Incluso en el caso de que llegue la AGI, <strong>no ser√° m√°s que una herramienta</strong> que podremos usar. El problema ser√° en su uso, pero no en que la propia AGI nos quiera exterminar:</p>

<blockquote>
<p>"La inteligencia en s√≠ misma es solo una herramienta. Es solo una forma de lograr objetivos. Si no la conectas con la capacidad de establecer objetivos aut√≥nomos, entonces es bastante inofensiva. No es completamente inofensiva porque estar√° en manos de humanos y los humanos son peligrosos. As√≠ que es peligrosa en ese sentido, ya que las personas podr√≠an usarla potencialmente con malos prop√≥sitos, pero no es peligrosa en el sentido de que compita con la especie humana."</p>

</blockquote>

<p>4Ô∏è‚É£ En la segunda quincena de junio se han<strong> lanzado dos nuevos LLMs</strong> interesantes: Anthropic ha lanzado&nbsp;<a href="https://www.anthropic.com/news/claude-3-5-sonnet">Claude Sonnet 3.5</a>&nbsp;y Google ha lanzado el modelo open source de 27B&nbsp;<a href="https://blog.google/technology/developers/google-gemma-2/">Gemma-2</a>.</p>

<p>Ambos lanzamientos siguen la tendencia de las √∫ltimas semanas de lanzar modelos peque√±os mejor entrenados. El modelo de Anthropic es la siguiente versi√≥n del modelo mediano de la familia Claude y el modelo de Google es la siguiente versi√≥n de su modelo abierto Gemma.</p>

<p>Hace solo tres meses (<a href="/posts/del-1-al-15-de-marzo-5-de-2024/">numero 5 de 2024</a>) coment√°bamos que Anthropic hab√≠a lanzado su familia 3.0 de modelos: Haiku, Sonnet y Opus. El √∫ltimo era el m√°s potente, en la liga de GPT-4. Los modelos Sonnet y Haiku son modelos m√°s peque√±os, m√°s r√°pidos y m√°s baratos en coste de inferencia.</p>

<p>Solo tres meses despu√©s Anthropic publica la siguiente figura:</p>

<p>
<img src="966072e9-3092-46d9-aa40-e2051b8de4b2_2200x1174.webp" alt="">
</p>

<p>Los modelos peque√±os a la caza de los mayores.</p>

<p>Sonnet ahora es el modelo m√°s potente de Antrhopic, superando a un modelo de mayor. Pas√≥ lo mismo con Gemini 1.5 Pro (del que hablamos en el&nbsp;<a href="/posts/del-16-al-29-de-febrero-4-de-2024/">n√∫mero 4 de 2024</a>). Google sac√≥ la siguiente versi√≥n del modelo mediano (el Pro), dejando para el futuro la del modelo m√°s grande, el Ultra.</p>

<p>Anthropic muestra las siguientes puntuaciones de Sonnet 3.5 en los&nbsp;<em>benchmarks</em>&nbsp;m√°s populares, superando a Opus 3 y, en muchos casos, a GPT-4o, el modelo l√≠der de OpenAI en la actualidad.</p>

<p>
<img src="1e8b5648-03b8-4492-9dd9-11771763fb04_2200x1894.webp" alt="">
</p>

<p>Sonnet tambi√©n es multimodal, capaz de interpretar im√°genes. Y Anthropic lo ha lanzado junto con la funcionalidad llamada&nbsp;<em>artifacts</em>, una ventana junto a la conversaci√≥n en la que el modelo puede ejecutar c√≥digo. </p>

<p>Por ejemplo, la siguiente pel√≠cula es el resultado de una sesi√≥n en la he ido indicando a Sonnet <strong>c√≥mo crear un juego</strong>. El planteamiento inicial era mover un cuadrado azul por la pantalla y hemos terminado haciendo <strong>una versi√≥n libre de Pong</strong>. Sonnet generaba el c√≥digo y yo iba coment√°ndole funcionalidades a a√±adir, del tipo de "Haz que aparezca una estrella que hay que evitar". O "El juego es un poco aburrido, haz que vayan aumentando el n√∫mero de estrellas". El resultado final (y todo el proceso) es incre√≠ble.</p>

<div class="native-video-embed" data-component-name="VideoPlaceholder" data-attrs="{&quot;mediaUploadId&quot;:&quot;266f971e-0b34-4f8b-ac11-ac9b35630e7b&quot;,&quot;duration&quot;:null}">
</div>
<p>
</p>

<p>5Ô∏è‚É£ Termino con una reflexi√≥n sobre la <strong>evoluci√≥n de los LLMs</strong>. En un&nbsp;<a href="https://x.com/DrJimFan/status/1805265388256837842">post en X</a>&nbsp;Jim Fan publica la siguiente imagen:</p>

<p>
<img src="60280659-5c6f-4d7a-b8d5-2246de11bd4a_2048x1152.jpeg" alt="">
</p>

<p>GPT-4 ya no es √∫nico.</p>

<p>Vemos que la imagen da respuesta a una de las preguntas que nos hac√≠amos a principios de a√±o: <strong>¬øera replicable GPT-4?</strong>. Cuando GPT-4&nbsp;<a href="https://openai.com/index/gpt-4-research/">se present√≥</a>&nbsp;en marzo de 2023 muchos nos preguntamos si el enorme salto con GPT-3.5 era debido a alg√∫n conocimiento exclusivo de OpenAI que ser√≠a dif√≠cil de replicar por otras empresas. Ha pasado ya un a√±o y la figura anterior nos muestra que la respuesta es que no, que OpenAI no tiene una receta exclusiva para hacer LLMs y que otras empresas (Google, Anthropic, Meta) han alcanzado o van a alcanzar pronto a GPT-4, incluso con modelos m√°s peque√±os.</p>

<p>Hab√≠a una segunda pregunta por responder. ¬ø<strong>Seguir√° escalando la inteligencia de los modelos</strong> cuando se hagan m√°s grandes? El n√∫mero de par√°metros de GPT-3.5 era de 175 mil millones (175B, <em>billions</em> en ingl√©s). OpenAI nunca ha desvelado el n√∫mero de par√°metros de GPT-4, pero al CEO de Nvidia, Jensen Huang,&nbsp;<a href="https://www.youtube.com/live/Y2F8yisiS6E?si=qXrAgcOS7M9iW3za&amp;t=1245">se le escap√≥</a>&nbsp;que era de 1,8T (1,8 billones en espa√±ol). Poni√©ndolo en las mismas unidades, tenemos a GPT-3.5 con 0,175T par√°metros y a GPT-4 1,8T par√°metros. O sea, que GPT-4 es un orden de magnitud mayor que GPT-3.5.</p>

<p>Todos estamos esperando el lanzamiento de GPT-5, el pr√≥ximo modelo grande de OpenAI. Presumiblemente, ser√° un orden de magnitud mayor, con alrededor de 20T par√°metros. Hay&nbsp;<a href="https://www.reddit.com/r/singularity/comments/1bi8rme/jensen_huang_just_gave_us_some_numbers_for_the/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button">algunas estimaciones</a>&nbsp;del tiempo necesario para realizar el entrenamiento de este modelo y de c√≥mo va a evolucionar este tiempo con las nuevas GPUs de Nvidia:</p>

<ul>
<li>
<p>OpenAI comenz√≥ a entrenar GPT-5 a finales de diciembre de 2023 usando GPUs H100.</p>

</li>
<li>
<p>Se espera que el entrenamiento dure 3 meses y que se complete para finales de marzo de 2024.</p>

</li>
<li>
<p>Para GPT-5, se predice el uso de al menos 50,000 GPUs H100, en comparaci√≥n con las 20,000 A100 usadas para GPT-4.</p>

</li>
<li>
<p>El modelo tendr√° alrededor de 20T de par√°metros.</p>

</li>
<li>
<p>El proceso de afinamiento y pruebas adicionales tomar√≠a de 3 a 5 meses, con una posible fecha de lanzamiento en julio o agosto de 2024.</p>

</li>
<li>
<p>Microsoft podr√≠a tener acceso a 500,000 GPUs H100 para finales de 2024</p>

</li>
<li>
<p>OpenAI podr√≠a usar hasta 250,000 GPUs H100 para entrenar un modelo de 50T de par√°metros en el tercer trimestre de 2024.</p>

</li>
<li>
<p>Existe la posibilidad de lanzar un modelo intermedio (GPT-4.5) con 10T de par√°metros y retrasar GPT-5 hasta diciembre de 2024.</p>

</li>
<li>
<p>La llegada de GPUs B200 para finales de 2024 permitir√° entrenar modelos con decenas de billones de par√°metros (20T, 30T, 40T, ... par√°metros).</p>

</li>
</ul>

<p>Todas las grandes tecnol√≥gicas est√°n en esta carrera y, por eso, Nvidia es actualmente la empresa tecnol√≥gica con mayor capitalizaci√≥n. No dan abasto vendiendo GPUs.</p>

<p>Dentro de poco, cuando se hagan p√∫blicos estos modelos que se est√°n entrenando en la actualidad, veremos si el salto de magnitud en n√∫mero de par√°metros representa tambi√©n un salto de magnitud en "inteligencia", y si se sigue cumpliendo la&nbsp;<a href="https://www.aisnakeoil.com/p/ai-scaling-myths">ley de escalado</a>&nbsp;de los modelos de lenguaje.</p>

<p>Ya hay alguna diapositiva que&nbsp;<a href="https://www.youtube.com/live/vaIiNZoXymg?si=-sOVrgNN-Sc6G10Z&amp;t=26615">est√° siendo usada</a>&nbsp;por gente de OpenAI que pronostica que el salto va a ser enorme:</p>

<p>
<img src="d061fa44-44fa-42e0-8a65-267e3d18e53c_1989x1125.jpeg" alt="">
</p>

<p>Y tambi√©n van en esta l√≠nea las √∫ltimas declaraciones de personas que seguro que ha tenido contacto con los primeros resultados de estos nuevos modelos, como Bill Gates, Dario Amodei o Demis Hassabis. </p>

<p>Por ejemplo, Gates habla de las dos siguientes generaciones LLMs en el siguiente v√≠deo, sacado de una interesante conversaci√≥n mucho m√°s larga, disponible en&nbsp;<a href="https://www.youtube.com/watch?v=jrTYdOEaiy0">YouTube</a>. Es un v√≠deo editado y publicado en X por <a href="https://x.com/tsarnick">Tsarathustra</a> (no os dej√©is enga√±ar por el t√≠tulo, publica v√≠deos y noticias muy interesantes).</p>

<div class="native-video-embed" data-component-name="VideoPlaceholder" data-attrs="{&quot;mediaUploadId&quot;:&quot;def2c556-8306-4134-af81-12ae5adfe26b&quot;,&quot;duration&quot;:null}">
</div>
<p>Gates dice dos cosas importantes: primero, va a haber un salto importante en las dos siguientes generaciones de LLMs (llam√©moslas GPT-5 y GPT-6). Para este salto se va a necesitar aumentar tambi√©n en √≥rdenes de magnitud los datos de entrenamiento y se va a tener que usar v√≠deo<a class="footnote-anchor" data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1" href="#footnote-1" target="_self">1</a>. </p>

<p>Lo segundo que comenta es muy similar a lo que comentamos antes de Chollet (y lo que siempre ha mantenido <a href="https://time.com/6694432/yann-lecun-meta-ai-interview/">LeCun</a>): escalar los LLMs va a producir mejoras, pero no nos va a traer la AGI. Para eso va a ser necesario desarrollar otros algoritmos y estrategias que permitan implementar ‚Äúmeta-cognici√≥n‚Äù que permita a la IA reflexionar sobre los pensamientos que est√° generando.</p>

<p>¬øPermitir√° el escalado acercarse a la AGI? ¬øO estamos viendo ya sus l√≠mites? Yo creo que todav√≠a <strong>es pronto para sacar una conclusi√≥n definitiva</strong>. Creo que la idea de Chollet de que los LLMs aprenden patrones de programas permite argumentar que LLMs m√°s grandes y mejor entrenados <strong>pueden generalizar mejor</strong> esos patrones, no solo aumentar su n√∫mero. Y los problemas que siempre ha comentado LeCun de que el texto no es suficiente para aprender un modelo f√≠sico del mundo puede que sean superados cuando se entrene a los LLMs directamente con secuencias de v√≠deo, quiz√°s dentro de un par de generaciones (GPT-6 o GPT-7). O quiz√°s tienen raz√≥n LeCun y Chollet y <strong>ya hemos llegado al tope</strong> de lo que se puede hacer con la tecnolog√≠a de los LLMs y los transformers. </p>

<p>Como siempre decimos por aqu√≠, lo veremos. Todav√≠a es pronto para saberlo, podremos decir algo m√°s definitivo dentro de tres o cuatro a√±os. Mientras tanto, siempre podemos <a href="https://manifold.markets/RemNi/will-we-get-agi-before-2030">hacer apuestas</a>.</p>

<h2>üë∑‚Äç‚ôÇÔ∏èMis quince d√≠as</h2>

<h3>üçøCine</h3>

<p>Me decepcion√≥ un poco <em>
<a href="https://letterboxd.com/domingogallardo/film/a-quiet-place-day-one/">Un lugar tranquilo: D√≠a 1</a>
</em>. La vi un poco lenta y aburrida y no termin√© de conectar. M√°s floja que las anteriores. Y me divert√≠ mucho con <em>
<a href="https://letterboxd.com/domingogallardo/film/under-paris/">En las profundidades del Sena</a>
</em> en Netflix. Una peli de tiburones, de las que les gustar√≠a a <strong>Claire y Phil</strong>.</p>

<p>De todas las de la quincena, destaco <em>
<a href="https://letterboxd.com/domingogallardo/film/the-greatest-hits/">The Greatest Hits</a>
</em>, en Disney. Una bonita historia de amor, m√∫sica y saltos temporales. Es la segunda pel√≠cula del director <strong>Ned Benson</strong> y tiene como int√©rpretes a un tr√≠o de chicos guap√≠simos: la estupenda <strong>Lucy Boynton</strong> (protagonista tambi√©n de otra peli que vi hace poco y que tambi√©n me encant√≥: <a href="https://letterboxd.com/domingogallardo/film/sing-street/">Sing Street</a>), el pr√≥ximo <em>Superman</em>, <strong>David Corenswet</strong>, y <strong>Justin H. Min</strong>, que me sonaba de haberlo visto en <em>The Unmbrella Academy</em>.</p>

<p>
<img src="70b37988-de18-47e5-a6a1-d3f8cbae030b_599x887.jpeg" alt="">
</p>

<p>Tengo que hacer una lista en Letterboxd con todas las pel√≠culas y series de este tipo que me han encantado: <em>
<strong>Begin Again</strong>
</em>, <em>
<strong>Sing Street</strong>
</em> o<em>
<strong> Daisy Jones</strong>
</em> (y <em>
<strong>School of Rock</strong>
</em>, why not!). ¬°Bueno, <a href="https://letterboxd.com/domingogallardo/list/music-love/">ya la he hecho</a>! üòÑ</p>

<h3>üì∫ TV</h3>

<p>Muy entretenida la serie de Apple TV+ <strong>Materia Oscura</strong>. Nos ha gustado mucho.</p>

<p>
<img src="a1723ce5-ace2-42fa-9a6e-56487bac1e1d_800x1200.jpeg" alt="">
</p>

<p>Como siempre con Apple, una producci√≥n excelente. Y sobre la tem√°tica, a pesar de que el concepto de multiverso est√° ya demasiado gastado, no recuerdo muchas pel√≠culas ni series que lo traten demasiado bien (lo siento, no he visto <em>Fringe</em>). Pero esta historia de <strong>Blake Crouch</strong> s√≠ lo hace de una forma solvente. Es bastante original, tiene buenos giros que sorprenden y el multiverso no es una excusa, sino que es el elemento principal de la historia. Muy bien <strong>Joel Edgerton</strong> y <strong>Jimmi Simpson</strong>. Y correctas <strong>Jennifer Connelly</strong> y <strong>Alice Braga</strong>, tampoco daban para mucho m√°s sus personajes.</p>

<div>
<hr>

</div>
<p>¬°Hasta la pr√≥xima quincena, nos leemos! üëãüëã</p>

<div class="footnote" data-component-name="FootnoteToDOM">
<a id="footnote-1" href="#footnote-anchor-1" class="footnote-number" contenteditable="false" target="_self">1</a>
<div class="footnote-content">
<p>Aunque los LLMs m√°s avanzados son multimodales, no se han entrenado realmente con secuencias completas de v√≠deo, sino con instant√°neas, im√°genes est√°ticas extra√≠das del v√≠deo. El cine ha demostrado que necesitamos al menos 24 im√°genes por segundo para percibir un movimiento como continuo. Seguro que no son necesarios tantos FPS (<em>frames por segundo</em>) para entrenar los LLM con v√≠deo. Pero incluso para un entrenamiento con 5 o 10 FPS se necesitar√≠a una capacidad de c√°lculo dos o tres ordenes de magnitud mayor que en la actualidad.</p>

<p>
</p>

</div>
</div>
